{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "covidClassifierCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zv-YmR8r7-g2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0c888ad5-c7eb-421d-a764-a294d54cafc6"
      },
      "source": [
        "!pip install biopython"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: biopython in /usr/local/lib/python3.6/dist-packages (1.77)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from biopython) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_1fVH1tIJy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install tensorflow"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoDA2Wt0wN0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from Bio.SeqIO import parse\n",
        "from Bio.SeqRecord import SeqRecord\n",
        "from Bio.Seq import Seq\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import re\n",
        "import math\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, LeakyReLU\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Conv1D, MaxPooling1D\n",
        "from collections import Counter\n",
        "from sklearn.utils import class_weight\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud_zFpqmwQO5",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "76f8cbdc-277a-4d74-cbf6-7aabc3e0de88"
      },
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "uploaded = files.upload()\n",
        "df = pd.read_csv(io.StringIO(uploaded['final_dates_reduced.csv'].decode('utf-8')))\n",
        "df.head(2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4b7d42fa-1fea-4f79-a38c-c2a5a6a3425b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4b7d42fa-1fea-4f79-a38c-c2a5a6a3425b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving final_dates_reduced.csv to final_dates_reduced (1).csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accession</th>\n",
              "      <th>Release_Date</th>\n",
              "      <th>Species</th>\n",
              "      <th>Length</th>\n",
              "      <th>Geo_Location</th>\n",
              "      <th>Host</th>\n",
              "      <th>Isolation_Source</th>\n",
              "      <th>Collection_Date</th>\n",
              "      <th>Sequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MT683386</td>\n",
              "      <td>2020-07-01T00:00:00Z</td>\n",
              "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
              "      <td>29858</td>\n",
              "      <td>USA</td>\n",
              "      <td>Homo sapiens</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apr-May</td>\n",
              "      <td>GGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MT683387</td>\n",
              "      <td>2020-07-01T00:00:00Z</td>\n",
              "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
              "      <td>29854</td>\n",
              "      <td>USA</td>\n",
              "      <td>Homo sapiens</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apr-May</td>\n",
              "      <td>ATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTTGTAGA...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Accession  ...                                           Sequence\n",
              "0  MT683386  ...  GGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTT...\n",
              "1  MT683387  ...  ATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTTGTAGA...\n",
              "\n",
              "[2 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FDMT3aOLBUT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "718181e3-0035-4401-8394-7029b44bcc9d"
      },
      "source": [
        "!pip install keras-metrics"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-metrics in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.6/dist-packages (from keras-metrics) (2.3.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.18.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.1.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (2.10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8UfrLJUczXK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "45f77f0f-0908-4581-c069-3cd788cd3d94"
      },
      "source": [
        "df3 = df.sample(frac=1).reset_index(drop=True)\n",
        "df3.head(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accession</th>\n",
              "      <th>Release_Date</th>\n",
              "      <th>Species</th>\n",
              "      <th>Length</th>\n",
              "      <th>Geo_Location</th>\n",
              "      <th>Host</th>\n",
              "      <th>Isolation_Source</th>\n",
              "      <th>Collection_Date</th>\n",
              "      <th>Sequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MT246463</td>\n",
              "      <td>2020-03-26T00:00:00Z</td>\n",
              "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
              "      <td>29782</td>\n",
              "      <td>USA: WA</td>\n",
              "      <td>Homo sapiens</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mar</td>\n",
              "      <td>GTATAATTAATAACTAATTACTGTCGTTGACAGGACACGAGTAACT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MT585050</td>\n",
              "      <td>2020-06-10T00:00:00Z</td>\n",
              "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
              "      <td>29826</td>\n",
              "      <td>USA: Michigan</td>\n",
              "      <td>Homo sapiens</td>\n",
              "      <td>swab</td>\n",
              "      <td>Apr-May</td>\n",
              "      <td>ACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAACTTTAAAATC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MT642381</td>\n",
              "      <td>2020-06-19T00:00:00Z</td>\n",
              "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
              "      <td>29858</td>\n",
              "      <td>USA: Washington, Pierce County</td>\n",
              "      <td>Homo sapiens</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apr-May</td>\n",
              "      <td>TACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTTGTAGAT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MT252688</td>\n",
              "      <td>2020-04-24T00:00:00Z</td>\n",
              "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
              "      <td>29864</td>\n",
              "      <td>USA: WA</td>\n",
              "      <td>Homo sapiens</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mar</td>\n",
              "      <td>ATTAAAGGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MT446355</td>\n",
              "      <td>2020-05-08T00:00:00Z</td>\n",
              "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
              "      <td>29807</td>\n",
              "      <td>USA: Slidell, LA</td>\n",
              "      <td>Homo sapiens</td>\n",
              "      <td>oronasopharynx</td>\n",
              "      <td>Apr-May</td>\n",
              "      <td>GTTCTCTAAACGAACTTTAAAATCTGTGTGGCTGTCACTCGGCTGC...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Accession  ...                                           Sequence\n",
              "0  MT246463  ...  GTATAATTAATAACTAATTACTGTCGTTGACAGGACACGAGTAACT...\n",
              "1  MT585050  ...  ACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAACTTTAAAATC...\n",
              "2  MT642381  ...  TACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTTGTAGAT...\n",
              "3  MT252688  ...  ATTAAAGGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGA...\n",
              "4  MT446355  ...  GTTCTCTAAACGAACTTTAAAATCTGTGTGGCTGTCACTCGGCTGC...\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trc5btZmYXim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def string_to_array(my_string):\n",
        "    my_string = my_string.lower()\n",
        "    my_string = re.sub('[^acgt]', 'z', my_string)\n",
        "    my_array = np.array(list(my_string))\n",
        "    return my_array"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2y2nZXZYb04",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "21446f5b-3d7d-4b0e-f0d0-9f135e9795b9"
      },
      "source": [
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(np.array(['a','c','g','t','z']))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mysuL1CgYb_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ordinal_encoder(my_array):\n",
        "    \n",
        "    integer_encoded = label_encoder.transform(my_array)\n",
        "    float_encoded = integer_encoded.astype(float)\n",
        "    float_encoded[float_encoded == 0] = 0.25 # A\n",
        "    float_encoded[float_encoded == 1] = 0.50 # C\n",
        "    float_encoded[float_encoded == 2] = 0.75 # G\n",
        "    float_encoded[float_encoded == 3] = 1.00 # T\n",
        "    float_encoded[float_encoded == 4] = 0.00 # anything else, z\n",
        "    \n",
        "    return float_encoded"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SxN0TDAYp7M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "56e955c3-df57-4cac-fd0b-50617a5b7894"
      },
      "source": [
        "data=df3[[\"Sequence\",\"Collection_Date\"]]\n",
        "data=data[data[\"Sequence\"].notna()]\n",
        "\n",
        "dummy=[]\n",
        "dum=np.array(dummy)\n",
        "\n",
        "form={\"inp_seq\":dum}\n",
        "\n",
        "seq_df = pd.DataFrame (form, columns = ['inp_seq'])\n",
        "\n",
        "seq_list=[]\n",
        "\n",
        "for idx, seq in enumerate(list(data[\"Sequence\"])):\n",
        "    arr=ordinal_encoder(string_to_array(seq))\n",
        "    seq_list.append(arr)\n",
        "    \n",
        "seq_df[\"inp_seq\"]=seq_list\n",
        "\n",
        "final_data= data.assign(enc_seq=seq_df)\n",
        "\n",
        "final_data=final_data[[\"enc_seq\",\"Collection_Date\"]]\n",
        "\n",
        "final_data"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>enc_seq</th>\n",
              "      <th>Collection_Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0.75, 1.0, 0.25, 1.0, 0.25, 0.25, 1.0, 1.0, 0...</td>\n",
              "      <td>Mar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[0.25, 0.5, 1.0, 1.0, 1.0, 0.5, 0.75, 0.25, 1....</td>\n",
              "      <td>Apr-May</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[1.0, 0.25, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 0.5,...</td>\n",
              "      <td>Apr-May</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0.25, 1.0, 1.0, 0.25, 0.25, 0.25, 0.75, 0.75,...</td>\n",
              "      <td>Mar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0.75, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.25, 0.2...</td>\n",
              "      <td>Apr-May</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5592</th>\n",
              "      <td>[0.75, 0.75, 1.0, 1.0, 1.0, 0.25, 1.0, 0.25, 0...</td>\n",
              "      <td>Apr-May</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5593</th>\n",
              "      <td>[1.0, 0.5, 0.5, 0.5, 0.25, 0.75, 0.75, 1.0, 0....</td>\n",
              "      <td>Apr-May</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5594</th>\n",
              "      <td>[1.0, 0.25, 0.25, 0.5, 0.25, 0.25, 0.25, 0.5, ...</td>\n",
              "      <td>Apr-May</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5595</th>\n",
              "      <td>[1.0, 0.5, 1.0, 0.5, 1.0, 0.25, 0.25, 0.25, 0....</td>\n",
              "      <td>Mar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5596</th>\n",
              "      <td>[0.75, 0.25, 1.0, 0.5, 1.0, 0.75, 1.0, 1.0, 0....</td>\n",
              "      <td>Mar</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5597 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                enc_seq Collection_Date\n",
              "0     [0.75, 1.0, 0.25, 1.0, 0.25, 0.25, 1.0, 1.0, 0...             Mar\n",
              "1     [0.25, 0.5, 1.0, 1.0, 1.0, 0.5, 0.75, 0.25, 1....         Apr-May\n",
              "2     [1.0, 0.25, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 0.5,...         Apr-May\n",
              "3     [0.25, 1.0, 1.0, 0.25, 0.25, 0.25, 0.75, 0.75,...             Mar\n",
              "4     [0.75, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.25, 0.2...         Apr-May\n",
              "...                                                 ...             ...\n",
              "5592  [0.75, 0.75, 1.0, 1.0, 1.0, 0.25, 1.0, 0.25, 0...         Apr-May\n",
              "5593  [1.0, 0.5, 0.5, 0.5, 0.25, 0.75, 0.75, 1.0, 0....         Apr-May\n",
              "5594  [1.0, 0.25, 0.25, 0.5, 0.25, 0.25, 0.25, 0.5, ...         Apr-May\n",
              "5595  [1.0, 0.5, 1.0, 0.5, 1.0, 0.25, 0.25, 0.25, 0....             Mar\n",
              "5596  [0.75, 0.25, 1.0, 0.5, 1.0, 0.75, 1.0, 1.0, 0....             Mar\n",
              "\n",
              "[5597 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4XSis1OYya1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_maxLen(enc_seq):\n",
        "    \n",
        "    max=0\n",
        "    for row in enc_seq:\n",
        "        #print(type(row))\n",
        "        if(len(row)>max):\n",
        "            max=len(row)\n",
        "    \n",
        "    return max"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj-48IzPY1v0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def append_arr(enc_seq, max_len):\n",
        "    \n",
        "    seq_l=list(enc_seq)\n",
        "    for i in range(len(seq_l),max_len):\n",
        "        seq_l.append(0)\n",
        "        \n",
        "    new_seq_ar=np.array(seq_l)\n",
        "\n",
        "        \n",
        "    return new_seq_ar"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg9pu_utY3sl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "ef3da656-99d2-4e8c-d37c-6545ef727415"
      },
      "source": [
        "import math\n",
        "\n",
        "max_len=get_maxLen(final_data[\"enc_seq\"])\n",
        "# print(\"max_len is\",max_len)\n",
        "# if max_len%2 !=0:\n",
        "#     max_len += 1\n",
        "max_len = 29929\n",
        "\n",
        "n = 1\n",
        "for i in range(1, math.floor(math.sqrt(max_len))):\n",
        "    if max_len%i==0:\n",
        "        n = i\n",
        "\n",
        "padded_seq_list=[]\n",
        "\n",
        "for index, row in final_data.iterrows():\n",
        "    seq_ar=append_arr(row[\"enc_seq\"],max_len)\n",
        "    padded_seq_list.append(seq_ar)\n",
        "\n",
        "dummy=[]\n",
        "dum=np.array(dummy)\n",
        "form={\"padded_enc_seq\":dum}\n",
        "padded_seq_df = pd.DataFrame (form, columns = ['padded_enc_seq'])\n",
        "\n",
        "padded_seq_df[\"padded_enc_seq\"]=padded_seq_list\n",
        "\n",
        "padded_final_data= final_data.assign(padded_enc_seq=padded_seq_df)\n",
        "\n",
        "padded_final_data=padded_final_data[[\"padded_enc_seq\",\"Collection_Date\"]]\n",
        "\n",
        "padded_final_data.head(5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>padded_enc_seq</th>\n",
              "      <th>Collection_Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0.75, 1.0, 0.25, 1.0, 0.25, 0.25, 1.0, 1.0, 0...</td>\n",
              "      <td>Mar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[0.25, 0.5, 1.0, 1.0, 1.0, 0.5, 0.75, 0.25, 1....</td>\n",
              "      <td>Apr-May</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[1.0, 0.25, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 0.5,...</td>\n",
              "      <td>Apr-May</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0.25, 1.0, 1.0, 0.25, 0.25, 0.25, 0.75, 0.75,...</td>\n",
              "      <td>Mar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0.75, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.25, 0.2...</td>\n",
              "      <td>Apr-May</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      padded_enc_seq Collection_Date\n",
              "0  [0.75, 1.0, 0.25, 1.0, 0.25, 0.25, 1.0, 1.0, 0...             Mar\n",
              "1  [0.25, 0.5, 1.0, 1.0, 1.0, 0.5, 0.75, 0.25, 1....         Apr-May\n",
              "2  [1.0, 0.25, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 0.5,...         Apr-May\n",
              "3  [0.25, 1.0, 1.0, 0.25, 0.25, 0.25, 0.75, 0.75,...             Mar\n",
              "4  [0.75, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.25, 0.2...         Apr-May"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9c0MjlmY62r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reshape_seq(seq, m ,n):\n",
        "    \n",
        "    r_seq=np.reshape(seq,(m,n))\n",
        "    \n",
        "    return r_seq\n",
        "\n",
        "re_seqList=[]\n",
        "\n",
        "for index, row in padded_final_data.iterrows():\n",
        "    #seq_ar=reshape_seq(row[\"padded_enc_seq\"],n,max_len//n)\n",
        "    seq_ar=reshape_seq(row[\"padded_enc_seq\"],173, 173)\n",
        "    re_seqList.append(seq_ar)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HRrJbzQY9q_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f064f62d-f2db-429b-b34b-ac366b088c53"
      },
      "source": [
        "X = np.asarray(re_seqList)\n",
        "X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2], 1))\n",
        "X.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5597, 173, 173, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKbU-iFYY_pV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5e23cd4-ce1b-41bb-90da-4bae8a5ad089"
      },
      "source": [
        "Y = padded_final_data['Collection_Date'].values\n",
        "Y.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5597,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0ueOtHWZChW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loc_classes = list(Y)\n",
        "loc_classes = np.array(loc_classes) \n",
        "loc_classes = list(np.unique(loc_classes))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzBtd-yvZF-9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "2863b008-d69e-4de1-9e71-056590a9786a"
      },
      "source": [
        "for i, x in enumerate(loc_classes):\n",
        "    print(i, x)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Apr-May\n",
            "1 Jan-Feb\n",
            "2 Mar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N59F_bhxZIQW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "90d76536-55ee-4a1a-f7ab-249765111586"
      },
      "source": [
        "df2 = padded_final_data['Collection_Date'].apply(loc_classes.index)\n",
        "Y = df2.values\n",
        "Y.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5597,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy2A43YoZLVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.30)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pwtXoj8zOGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_best = Sequential()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21hGNcVup_YI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CheckMetrics(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.val_accs = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        X_val, Y_val = self.validation_data[0],self.validation_data[1]\n",
        "                \n",
        "        Y_val = np.argmax(Y_val,axis=1)\n",
        "        \n",
        "        Y_pred = self.model.predict(X_val)\n",
        "        Y_pred = np.argmax(Y_pred,axis=1)\n",
        "\n",
        "        _val_acc = accuracy_score(Y_val, Y_pred)\n",
        "\n",
        "        self.val_accs.append(_val_acc)\n",
        "        \n",
        "        if _val_acc == max(self.val_accs):\n",
        "            print(\"Validation Accuracy has improved. Saving Model.\")\n",
        "            self.model.save('modelCNN.h5')\n",
        "            model_best = self.model\n",
        "\n",
        "        return"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXdviXB7qA8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras_callbacks = CheckMetrics()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh-pWyLobXYQ",
        "colab_type": "text"
      },
      "source": [
        "K-Fold Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBYeZbsIbAZa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f52217cf-1b21-4e09-a53a-38ed79a86ff7"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
        "cvscores = []\n",
        "for train, test in kfold.split(X, Y):\n",
        "    batch_size = 32 \n",
        "    num_classes = 3\n",
        "    epochs = 29\n",
        "    img_rows, img_cols = X[train].shape[1], X[train].shape[2]\n",
        "    # X_train = X[train].reshape(X[train].shape[0],img_rows,img_cols,1)\n",
        "    # X_test = X[test].reshape(X[test].shape[0],img_rows,img_cols,1)\n",
        "    # convert class vectors to binary class matrices\n",
        "    Y_train = keras.utils.to_categorical(Y[train], num_classes)\n",
        "    Y_test = keras.utils.to_categorical(Y[test], num_classes)\n",
        "\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(img_rows, img_cols, 1)))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  \n",
        "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  \n",
        "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\t  # Compile model\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "\n",
        "    # Fit the model\n",
        "    history = model.fit(X[train], Y_train, batch_size=batch_size, epochs=300, verbose=1, validation_data=(X[test], Y_test), callbacks=[keras_callbacks])\n",
        " \n",
        "\t  # evaluate the model\n",
        "    model_sel = load_model('modelCNN.h5')\n",
        "    scores = model_sel.evaluate(X[test], Y_test, verbose=0)\n",
        "    #scores = model.evaluate(X[test], Y_test, verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (model_sel.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3731 samples, validate on 1866 samples\n",
            "Epoch 1/300\n",
            "3731/3731 [==============================] - 19s 5ms/step - loss: 0.8171 - accuracy: 0.5331 - val_loss: 0.7740 - val_accuracy: 0.5509\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 2/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.7843 - accuracy: 0.5403 - val_loss: 0.7763 - val_accuracy: 0.5509\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 3/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.7818 - accuracy: 0.5473 - val_loss: 0.7778 - val_accuracy: 0.5509\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 4/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.7819 - accuracy: 0.5481 - val_loss: 0.7790 - val_accuracy: 0.5509\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 5/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.7812 - accuracy: 0.5460 - val_loss: 0.7741 - val_accuracy: 0.5509\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 6/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.7771 - accuracy: 0.5441 - val_loss: 0.7757 - val_accuracy: 0.5509\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 7/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.7795 - accuracy: 0.5495 - val_loss: 0.7746 - val_accuracy: 0.5509\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 8/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.7803 - accuracy: 0.5481 - val_loss: 0.7792 - val_accuracy: 0.5509\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 9/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.7813 - accuracy: 0.5465 - val_loss: 0.7795 - val_accuracy: 0.5525\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 10/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.7633 - accuracy: 0.5674 - val_loss: 0.7274 - val_accuracy: 0.6115\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 11/300\n",
            "3731/3731 [==============================] - 11s 3ms/step - loss: 0.7168 - accuracy: 0.6189 - val_loss: 0.7323 - val_accuracy: 0.5777\n",
            "Epoch 12/300\n",
            "3731/3731 [==============================] - 11s 3ms/step - loss: 0.6971 - accuracy: 0.6307 - val_loss: 0.7362 - val_accuracy: 0.6109\n",
            "Epoch 13/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.6793 - accuracy: 0.6489 - val_loss: 0.7055 - val_accuracy: 0.6211\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 14/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.6643 - accuracy: 0.6526 - val_loss: 0.6917 - val_accuracy: 0.6265\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 15/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.6591 - accuracy: 0.6647 - val_loss: 0.7419 - val_accuracy: 0.6249\n",
            "Epoch 16/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.6452 - accuracy: 0.6786 - val_loss: 0.6894 - val_accuracy: 0.6479\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 17/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.6377 - accuracy: 0.6811 - val_loss: 0.6827 - val_accuracy: 0.6458\n",
            "Epoch 18/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.6339 - accuracy: 0.6835 - val_loss: 0.6958 - val_accuracy: 0.6490\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 19/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.6256 - accuracy: 0.6867 - val_loss: 0.6888 - val_accuracy: 0.6468\n",
            "Epoch 20/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.6126 - accuracy: 0.6896 - val_loss: 0.7357 - val_accuracy: 0.6576\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 21/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.6050 - accuracy: 0.7028 - val_loss: 0.6864 - val_accuracy: 0.6576\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 22/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.5891 - accuracy: 0.7044 - val_loss: 0.7354 - val_accuracy: 0.6527\n",
            "Epoch 23/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.5799 - accuracy: 0.7180 - val_loss: 0.6958 - val_accuracy: 0.6613\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 24/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.5658 - accuracy: 0.7199 - val_loss: 0.7267 - val_accuracy: 0.6779\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 25/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.5635 - accuracy: 0.7237 - val_loss: 0.6866 - val_accuracy: 0.6785\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 26/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.5518 - accuracy: 0.7221 - val_loss: 0.7262 - val_accuracy: 0.6726\n",
            "Epoch 27/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.5512 - accuracy: 0.7309 - val_loss: 0.7081 - val_accuracy: 0.6790\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 28/300\n",
            "3731/3731 [==============================] - 11s 3ms/step - loss: 0.5415 - accuracy: 0.7349 - val_loss: 0.7814 - val_accuracy: 0.6624\n",
            "Epoch 29/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.5348 - accuracy: 0.7400 - val_loss: 0.6771 - val_accuracy: 0.6736\n",
            "Epoch 30/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.5347 - accuracy: 0.7379 - val_loss: 0.7881 - val_accuracy: 0.6827\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 31/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.5162 - accuracy: 0.7446 - val_loss: 0.7723 - val_accuracy: 0.6677\n",
            "Epoch 32/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.5204 - accuracy: 0.7456 - val_loss: 0.7882 - val_accuracy: 0.6688\n",
            "Epoch 33/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.5135 - accuracy: 0.7446 - val_loss: 0.6878 - val_accuracy: 0.6710\n",
            "Epoch 34/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.5047 - accuracy: 0.7531 - val_loss: 0.8306 - val_accuracy: 0.6559\n",
            "Epoch 35/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.5051 - accuracy: 0.7464 - val_loss: 0.8706 - val_accuracy: 0.6736\n",
            "Epoch 36/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4989 - accuracy: 0.7540 - val_loss: 0.7918 - val_accuracy: 0.6817\n",
            "Epoch 37/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4994 - accuracy: 0.7598 - val_loss: 0.7807 - val_accuracy: 0.6608\n",
            "Epoch 38/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4892 - accuracy: 0.7545 - val_loss: 0.8541 - val_accuracy: 0.6806\n",
            "Epoch 39/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4888 - accuracy: 0.7590 - val_loss: 0.7961 - val_accuracy: 0.6763\n",
            "Epoch 40/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4813 - accuracy: 0.7623 - val_loss: 0.9715 - val_accuracy: 0.6720\n",
            "Epoch 41/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4768 - accuracy: 0.7617 - val_loss: 0.8244 - val_accuracy: 0.6672\n",
            "Epoch 42/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4772 - accuracy: 0.7692 - val_loss: 0.8005 - val_accuracy: 0.6720\n",
            "Epoch 43/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4746 - accuracy: 0.7623 - val_loss: 0.8638 - val_accuracy: 0.6672\n",
            "Epoch 44/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4644 - accuracy: 0.7674 - val_loss: 0.8769 - val_accuracy: 0.6785\n",
            "Epoch 45/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4683 - accuracy: 0.7639 - val_loss: 0.8662 - val_accuracy: 0.6720\n",
            "Epoch 46/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4581 - accuracy: 0.7775 - val_loss: 1.1071 - val_accuracy: 0.6742\n",
            "Epoch 47/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4631 - accuracy: 0.7751 - val_loss: 0.8350 - val_accuracy: 0.6726\n",
            "Epoch 48/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4541 - accuracy: 0.7722 - val_loss: 1.1439 - val_accuracy: 0.6645\n",
            "Epoch 49/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4521 - accuracy: 0.7832 - val_loss: 0.9988 - val_accuracy: 0.6763\n",
            "Epoch 50/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4584 - accuracy: 0.7781 - val_loss: 0.9938 - val_accuracy: 0.6870\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 51/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4433 - accuracy: 0.7856 - val_loss: 1.0204 - val_accuracy: 0.6763\n",
            "Epoch 52/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4480 - accuracy: 0.7818 - val_loss: 1.1017 - val_accuracy: 0.6844\n",
            "Epoch 53/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4441 - accuracy: 0.7848 - val_loss: 1.0587 - val_accuracy: 0.6742\n",
            "Epoch 54/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4493 - accuracy: 0.7775 - val_loss: 0.8960 - val_accuracy: 0.6726\n",
            "Epoch 55/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4407 - accuracy: 0.7850 - val_loss: 1.1648 - val_accuracy: 0.6801\n",
            "Epoch 56/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4457 - accuracy: 0.7826 - val_loss: 1.1117 - val_accuracy: 0.6635\n",
            "Epoch 57/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4379 - accuracy: 0.7842 - val_loss: 1.1483 - val_accuracy: 0.6661\n",
            "Epoch 58/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4413 - accuracy: 0.7909 - val_loss: 1.1368 - val_accuracy: 0.6747\n",
            "Epoch 59/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4405 - accuracy: 0.7783 - val_loss: 1.1305 - val_accuracy: 0.6795\n",
            "Epoch 60/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4360 - accuracy: 0.7845 - val_loss: 0.9599 - val_accuracy: 0.6838\n",
            "Epoch 61/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4330 - accuracy: 0.7915 - val_loss: 1.2757 - val_accuracy: 0.6801\n",
            "Epoch 62/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4366 - accuracy: 0.7840 - val_loss: 1.0609 - val_accuracy: 0.6779\n",
            "Epoch 63/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4354 - accuracy: 0.7856 - val_loss: 1.0860 - val_accuracy: 0.6827\n",
            "Epoch 64/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4284 - accuracy: 0.7818 - val_loss: 1.0647 - val_accuracy: 0.6742\n",
            "Epoch 65/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4305 - accuracy: 0.7936 - val_loss: 1.2413 - val_accuracy: 0.6790\n",
            "Epoch 66/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4308 - accuracy: 0.7880 - val_loss: 1.2198 - val_accuracy: 0.6827\n",
            "Epoch 67/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4258 - accuracy: 0.7936 - val_loss: 1.1816 - val_accuracy: 0.6785\n",
            "Epoch 68/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4329 - accuracy: 0.7899 - val_loss: 1.2096 - val_accuracy: 0.6624\n",
            "Epoch 69/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4259 - accuracy: 0.7931 - val_loss: 1.2446 - val_accuracy: 0.6683\n",
            "Epoch 70/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4226 - accuracy: 0.7942 - val_loss: 1.2505 - val_accuracy: 0.6640\n",
            "Epoch 71/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4275 - accuracy: 0.7883 - val_loss: 1.2242 - val_accuracy: 0.6779\n",
            "Epoch 72/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4254 - accuracy: 0.7952 - val_loss: 1.1077 - val_accuracy: 0.6742\n",
            "Epoch 73/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4193 - accuracy: 0.7899 - val_loss: 1.2038 - val_accuracy: 0.6720\n",
            "Epoch 74/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4231 - accuracy: 0.7909 - val_loss: 1.4280 - val_accuracy: 0.6790\n",
            "Epoch 75/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4204 - accuracy: 0.7909 - val_loss: 1.1488 - val_accuracy: 0.6720\n",
            "Epoch 76/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4206 - accuracy: 0.7934 - val_loss: 1.2616 - val_accuracy: 0.6661\n",
            "Epoch 77/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4170 - accuracy: 0.7952 - val_loss: 1.2760 - val_accuracy: 0.6693\n",
            "Epoch 78/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4130 - accuracy: 0.7974 - val_loss: 1.5135 - val_accuracy: 0.6774\n",
            "Epoch 79/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4164 - accuracy: 0.7992 - val_loss: 1.2394 - val_accuracy: 0.6801\n",
            "Epoch 80/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4128 - accuracy: 0.7990 - val_loss: 1.3996 - val_accuracy: 0.6844\n",
            "Epoch 81/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4076 - accuracy: 0.7992 - val_loss: 1.2301 - val_accuracy: 0.6833\n",
            "Epoch 82/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4064 - accuracy: 0.7992 - val_loss: 1.4233 - val_accuracy: 0.6838\n",
            "Epoch 83/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4074 - accuracy: 0.7958 - val_loss: 1.3950 - val_accuracy: 0.6860\n",
            "Epoch 84/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4101 - accuracy: 0.8022 - val_loss: 1.3373 - val_accuracy: 0.6881\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 85/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4057 - accuracy: 0.8046 - val_loss: 1.2670 - val_accuracy: 0.6849\n",
            "Epoch 86/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3943 - accuracy: 0.8011 - val_loss: 1.2887 - val_accuracy: 0.6865\n",
            "Epoch 87/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3948 - accuracy: 0.8076 - val_loss: 1.2807 - val_accuracy: 0.6919\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 88/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3936 - accuracy: 0.8049 - val_loss: 1.3033 - val_accuracy: 0.6924\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 89/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3930 - accuracy: 0.8102 - val_loss: 1.4480 - val_accuracy: 0.6935\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 90/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3863 - accuracy: 0.8019 - val_loss: 1.4652 - val_accuracy: 0.6919\n",
            "Epoch 91/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3867 - accuracy: 0.8113 - val_loss: 1.3485 - val_accuracy: 0.6865\n",
            "Epoch 92/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3797 - accuracy: 0.8143 - val_loss: 1.3317 - val_accuracy: 0.6860\n",
            "Epoch 93/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3829 - accuracy: 0.8161 - val_loss: 1.6209 - val_accuracy: 0.6977\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 94/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3827 - accuracy: 0.8068 - val_loss: 1.2113 - val_accuracy: 0.6854\n",
            "Epoch 95/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3805 - accuracy: 0.8215 - val_loss: 1.5231 - val_accuracy: 0.7063\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 96/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3805 - accuracy: 0.8135 - val_loss: 1.5180 - val_accuracy: 0.6924\n",
            "Epoch 97/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3788 - accuracy: 0.8129 - val_loss: 1.4511 - val_accuracy: 0.7004\n",
            "Epoch 98/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3739 - accuracy: 0.8185 - val_loss: 1.2995 - val_accuracy: 0.6967\n",
            "Epoch 99/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3663 - accuracy: 0.8196 - val_loss: 1.2890 - val_accuracy: 0.6977\n",
            "Epoch 100/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3621 - accuracy: 0.8199 - val_loss: 1.5791 - val_accuracy: 0.7031\n",
            "Epoch 101/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3702 - accuracy: 0.8223 - val_loss: 1.5921 - val_accuracy: 0.6983\n",
            "Epoch 102/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3616 - accuracy: 0.8252 - val_loss: 1.6315 - val_accuracy: 0.6945\n",
            "Epoch 103/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3625 - accuracy: 0.8362 - val_loss: 1.2673 - val_accuracy: 0.7069\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 104/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3601 - accuracy: 0.8244 - val_loss: 1.4950 - val_accuracy: 0.6994\n",
            "Epoch 105/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3620 - accuracy: 0.8266 - val_loss: 1.2373 - val_accuracy: 0.6999\n",
            "Epoch 106/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3591 - accuracy: 0.8277 - val_loss: 1.3857 - val_accuracy: 0.6983\n",
            "Epoch 107/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3507 - accuracy: 0.8301 - val_loss: 1.7328 - val_accuracy: 0.7122\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 108/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3502 - accuracy: 0.8346 - val_loss: 1.1095 - val_accuracy: 0.6994\n",
            "Epoch 109/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3513 - accuracy: 0.8322 - val_loss: 1.8138 - val_accuracy: 0.6988\n",
            "Epoch 110/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3458 - accuracy: 0.8346 - val_loss: 1.6250 - val_accuracy: 0.7020\n",
            "Epoch 111/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3439 - accuracy: 0.8330 - val_loss: 1.5355 - val_accuracy: 0.7031\n",
            "Epoch 112/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3370 - accuracy: 0.8386 - val_loss: 1.5784 - val_accuracy: 0.6977\n",
            "Epoch 113/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3440 - accuracy: 0.8336 - val_loss: 1.5986 - val_accuracy: 0.7058\n",
            "Epoch 114/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3417 - accuracy: 0.8344 - val_loss: 1.5891 - val_accuracy: 0.7031\n",
            "Epoch 115/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3486 - accuracy: 0.8336 - val_loss: 1.5780 - val_accuracy: 0.7133\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 116/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3301 - accuracy: 0.8397 - val_loss: 1.7787 - val_accuracy: 0.6994\n",
            "Epoch 117/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3495 - accuracy: 0.8370 - val_loss: 1.4686 - val_accuracy: 0.6999\n",
            "Epoch 118/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3333 - accuracy: 0.8435 - val_loss: 1.6096 - val_accuracy: 0.7063\n",
            "Epoch 119/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3212 - accuracy: 0.8427 - val_loss: 1.4839 - val_accuracy: 0.7095\n",
            "Epoch 120/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3222 - accuracy: 0.8502 - val_loss: 2.4278 - val_accuracy: 0.7036\n",
            "Epoch 121/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3262 - accuracy: 0.8496 - val_loss: 1.9080 - val_accuracy: 0.7117\n",
            "Epoch 122/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3246 - accuracy: 0.8462 - val_loss: 1.9336 - val_accuracy: 0.7079\n",
            "Epoch 123/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3238 - accuracy: 0.8486 - val_loss: 1.3690 - val_accuracy: 0.7133\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 124/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3110 - accuracy: 0.8496 - val_loss: 1.5870 - val_accuracy: 0.7117\n",
            "Epoch 125/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3082 - accuracy: 0.8531 - val_loss: 1.5779 - val_accuracy: 0.7144\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 126/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3068 - accuracy: 0.8526 - val_loss: 2.0430 - val_accuracy: 0.7154\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 127/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3120 - accuracy: 0.8561 - val_loss: 1.4322 - val_accuracy: 0.7117\n",
            "Epoch 128/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3131 - accuracy: 0.8534 - val_loss: 1.5369 - val_accuracy: 0.7154\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 129/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3076 - accuracy: 0.8588 - val_loss: 1.9029 - val_accuracy: 0.7111\n",
            "Epoch 130/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3046 - accuracy: 0.8563 - val_loss: 2.3486 - val_accuracy: 0.7160\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 131/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3042 - accuracy: 0.8561 - val_loss: 1.8147 - val_accuracy: 0.7090\n",
            "Epoch 132/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3063 - accuracy: 0.8646 - val_loss: 1.8950 - val_accuracy: 0.7085\n",
            "Epoch 133/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3050 - accuracy: 0.8585 - val_loss: 1.9000 - val_accuracy: 0.7144\n",
            "Epoch 134/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2957 - accuracy: 0.8579 - val_loss: 2.0006 - val_accuracy: 0.7074\n",
            "Epoch 135/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2995 - accuracy: 0.8622 - val_loss: 1.6133 - val_accuracy: 0.7122\n",
            "Epoch 136/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2978 - accuracy: 0.8590 - val_loss: 1.6251 - val_accuracy: 0.7203\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 137/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2999 - accuracy: 0.8617 - val_loss: 2.2327 - val_accuracy: 0.7176\n",
            "Epoch 138/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3087 - accuracy: 0.8617 - val_loss: 1.5875 - val_accuracy: 0.7181\n",
            "Epoch 139/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2821 - accuracy: 0.8649 - val_loss: 2.3835 - val_accuracy: 0.7144\n",
            "Epoch 140/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2903 - accuracy: 0.8625 - val_loss: 1.8341 - val_accuracy: 0.7085\n",
            "Epoch 141/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2892 - accuracy: 0.8665 - val_loss: 2.3310 - val_accuracy: 0.7144\n",
            "Epoch 142/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2904 - accuracy: 0.8644 - val_loss: 2.2492 - val_accuracy: 0.7144\n",
            "Epoch 143/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2890 - accuracy: 0.8644 - val_loss: 1.8241 - val_accuracy: 0.7133\n",
            "Epoch 144/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2926 - accuracy: 0.8716 - val_loss: 1.7039 - val_accuracy: 0.7106\n",
            "Epoch 145/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2854 - accuracy: 0.8668 - val_loss: 1.5609 - val_accuracy: 0.7165\n",
            "Epoch 146/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2774 - accuracy: 0.8679 - val_loss: 2.1508 - val_accuracy: 0.7192\n",
            "Epoch 147/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2804 - accuracy: 0.8759 - val_loss: 1.6044 - val_accuracy: 0.7010\n",
            "Epoch 148/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2806 - accuracy: 0.8689 - val_loss: 2.2657 - val_accuracy: 0.7085\n",
            "Epoch 149/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2802 - accuracy: 0.8738 - val_loss: 2.0873 - val_accuracy: 0.6988\n",
            "Epoch 150/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2748 - accuracy: 0.8730 - val_loss: 1.9982 - val_accuracy: 0.6999\n",
            "Epoch 151/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2719 - accuracy: 0.8759 - val_loss: 2.1833 - val_accuracy: 0.7149\n",
            "Epoch 152/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2706 - accuracy: 0.8727 - val_loss: 1.7582 - val_accuracy: 0.7074\n",
            "Epoch 153/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2729 - accuracy: 0.8789 - val_loss: 2.1088 - val_accuracy: 0.6999\n",
            "Epoch 154/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2710 - accuracy: 0.8713 - val_loss: 1.8522 - val_accuracy: 0.7058\n",
            "Epoch 155/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2751 - accuracy: 0.8692 - val_loss: 1.8461 - val_accuracy: 0.7058\n",
            "Epoch 156/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2655 - accuracy: 0.8751 - val_loss: 1.7223 - val_accuracy: 0.7095\n",
            "Epoch 157/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2641 - accuracy: 0.8783 - val_loss: 1.9697 - val_accuracy: 0.7090\n",
            "Epoch 158/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2614 - accuracy: 0.8791 - val_loss: 2.2246 - val_accuracy: 0.7053\n",
            "Epoch 159/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2634 - accuracy: 0.8764 - val_loss: 2.2347 - val_accuracy: 0.7063\n",
            "Epoch 160/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2582 - accuracy: 0.8775 - val_loss: 2.2824 - val_accuracy: 0.7074\n",
            "Epoch 161/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2637 - accuracy: 0.8778 - val_loss: 1.9874 - val_accuracy: 0.7031\n",
            "Epoch 162/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2635 - accuracy: 0.8807 - val_loss: 2.0661 - val_accuracy: 0.7058\n",
            "Epoch 163/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2647 - accuracy: 0.8805 - val_loss: 1.8576 - val_accuracy: 0.6999\n",
            "Epoch 164/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2597 - accuracy: 0.8799 - val_loss: 2.0426 - val_accuracy: 0.7069\n",
            "Epoch 165/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2547 - accuracy: 0.8837 - val_loss: 1.9375 - val_accuracy: 0.6956\n",
            "Epoch 166/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2575 - accuracy: 0.8738 - val_loss: 2.3086 - val_accuracy: 0.7165\n",
            "Epoch 167/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2548 - accuracy: 0.8874 - val_loss: 2.3701 - val_accuracy: 0.6988\n",
            "Epoch 168/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2519 - accuracy: 0.8829 - val_loss: 2.3767 - val_accuracy: 0.7095\n",
            "Epoch 169/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2578 - accuracy: 0.8837 - val_loss: 1.4908 - val_accuracy: 0.7074\n",
            "Epoch 170/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2590 - accuracy: 0.8826 - val_loss: 2.2834 - val_accuracy: 0.7074\n",
            "Epoch 171/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2494 - accuracy: 0.8893 - val_loss: 1.9553 - val_accuracy: 0.7020\n",
            "Epoch 172/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2489 - accuracy: 0.8821 - val_loss: 2.0708 - val_accuracy: 0.7058\n",
            "Epoch 173/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2456 - accuracy: 0.8818 - val_loss: 2.0112 - val_accuracy: 0.7176\n",
            "Epoch 174/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2578 - accuracy: 0.8853 - val_loss: 2.1757 - val_accuracy: 0.7047\n",
            "Epoch 175/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2397 - accuracy: 0.8872 - val_loss: 2.5721 - val_accuracy: 0.7111\n",
            "Epoch 176/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2491 - accuracy: 0.8842 - val_loss: 2.6308 - val_accuracy: 0.7101\n",
            "Epoch 177/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2573 - accuracy: 0.8858 - val_loss: 2.0410 - val_accuracy: 0.7090\n",
            "Epoch 178/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2431 - accuracy: 0.8888 - val_loss: 2.3255 - val_accuracy: 0.7085\n",
            "Epoch 179/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2408 - accuracy: 0.8904 - val_loss: 2.6410 - val_accuracy: 0.7122\n",
            "Epoch 180/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2393 - accuracy: 0.8890 - val_loss: 2.7922 - val_accuracy: 0.7074\n",
            "Epoch 181/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2369 - accuracy: 0.8896 - val_loss: 2.4710 - val_accuracy: 0.7053\n",
            "Epoch 182/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2329 - accuracy: 0.8914 - val_loss: 2.6265 - val_accuracy: 0.7036\n",
            "Epoch 183/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2395 - accuracy: 0.8874 - val_loss: 2.6375 - val_accuracy: 0.7106\n",
            "Epoch 184/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2394 - accuracy: 0.8877 - val_loss: 1.9451 - val_accuracy: 0.7117\n",
            "Epoch 185/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2395 - accuracy: 0.8898 - val_loss: 2.2778 - val_accuracy: 0.7047\n",
            "Epoch 186/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2345 - accuracy: 0.8872 - val_loss: 2.1688 - val_accuracy: 0.7042\n",
            "Epoch 187/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2391 - accuracy: 0.8898 - val_loss: 2.3956 - val_accuracy: 0.7106\n",
            "Epoch 188/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2429 - accuracy: 0.8856 - val_loss: 2.0912 - val_accuracy: 0.7036\n",
            "Epoch 189/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2235 - accuracy: 0.8963 - val_loss: 2.9711 - val_accuracy: 0.7085\n",
            "Epoch 190/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2381 - accuracy: 0.8896 - val_loss: 2.1745 - val_accuracy: 0.7085\n",
            "Epoch 191/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2315 - accuracy: 0.8912 - val_loss: 2.2117 - val_accuracy: 0.7004\n",
            "Epoch 192/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2359 - accuracy: 0.8882 - val_loss: 2.4785 - val_accuracy: 0.7053\n",
            "Epoch 193/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2297 - accuracy: 0.8944 - val_loss: 2.2427 - val_accuracy: 0.7128\n",
            "Epoch 194/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2220 - accuracy: 0.8923 - val_loss: 2.6636 - val_accuracy: 0.6999\n",
            "Epoch 195/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2283 - accuracy: 0.8957 - val_loss: 2.5967 - val_accuracy: 0.7128\n",
            "Epoch 196/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2293 - accuracy: 0.8957 - val_loss: 2.7337 - val_accuracy: 0.7106\n",
            "Epoch 197/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2329 - accuracy: 0.8904 - val_loss: 3.1080 - val_accuracy: 0.6961\n",
            "Epoch 198/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2219 - accuracy: 0.8960 - val_loss: 3.1854 - val_accuracy: 0.7106\n",
            "Epoch 199/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2215 - accuracy: 0.8976 - val_loss: 2.7759 - val_accuracy: 0.6935\n",
            "Epoch 200/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2318 - accuracy: 0.8920 - val_loss: 3.2548 - val_accuracy: 0.7010\n",
            "Epoch 201/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2208 - accuracy: 0.8979 - val_loss: 2.8218 - val_accuracy: 0.6951\n",
            "Epoch 202/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2166 - accuracy: 0.9035 - val_loss: 2.7133 - val_accuracy: 0.7095\n",
            "Epoch 203/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2204 - accuracy: 0.9000 - val_loss: 3.2498 - val_accuracy: 0.6951\n",
            "Epoch 204/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2239 - accuracy: 0.8982 - val_loss: 2.3990 - val_accuracy: 0.7117\n",
            "Epoch 205/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2144 - accuracy: 0.9008 - val_loss: 2.6272 - val_accuracy: 0.7111\n",
            "Epoch 206/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2177 - accuracy: 0.8960 - val_loss: 2.5684 - val_accuracy: 0.7031\n",
            "Epoch 207/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2224 - accuracy: 0.9011 - val_loss: 2.6001 - val_accuracy: 0.7042\n",
            "Epoch 208/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2311 - accuracy: 0.9032 - val_loss: 2.3728 - val_accuracy: 0.7208\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 209/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2132 - accuracy: 0.9038 - val_loss: 3.4842 - val_accuracy: 0.7058\n",
            "Epoch 210/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2161 - accuracy: 0.9024 - val_loss: 3.0092 - val_accuracy: 0.7069\n",
            "Epoch 211/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2127 - accuracy: 0.9006 - val_loss: 2.6145 - val_accuracy: 0.7047\n",
            "Epoch 212/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2124 - accuracy: 0.9078 - val_loss: 3.4695 - val_accuracy: 0.7074\n",
            "Epoch 213/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2204 - accuracy: 0.8965 - val_loss: 2.3547 - val_accuracy: 0.7079\n",
            "Epoch 214/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2113 - accuracy: 0.9083 - val_loss: 2.4532 - val_accuracy: 0.7010\n",
            "Epoch 215/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1993 - accuracy: 0.9073 - val_loss: 2.6335 - val_accuracy: 0.7111\n",
            "Epoch 216/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2045 - accuracy: 0.9040 - val_loss: 2.7204 - val_accuracy: 0.7111\n",
            "Epoch 217/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2097 - accuracy: 0.9057 - val_loss: 3.1594 - val_accuracy: 0.7128\n",
            "Epoch 218/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2143 - accuracy: 0.9049 - val_loss: 2.7223 - val_accuracy: 0.7117\n",
            "Epoch 219/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2151 - accuracy: 0.9027 - val_loss: 2.8323 - val_accuracy: 0.7026\n",
            "Epoch 220/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2165 - accuracy: 0.9046 - val_loss: 2.8413 - val_accuracy: 0.7010\n",
            "Epoch 221/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2015 - accuracy: 0.9070 - val_loss: 2.5775 - val_accuracy: 0.7015\n",
            "Epoch 222/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2098 - accuracy: 0.9057 - val_loss: 3.2458 - val_accuracy: 0.7090\n",
            "Epoch 223/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2016 - accuracy: 0.9110 - val_loss: 3.0043 - val_accuracy: 0.7101\n",
            "Epoch 224/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2067 - accuracy: 0.9059 - val_loss: 2.6098 - val_accuracy: 0.6967\n",
            "Epoch 225/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1988 - accuracy: 0.9121 - val_loss: 3.2062 - val_accuracy: 0.7036\n",
            "Epoch 226/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2073 - accuracy: 0.9016 - val_loss: 2.9071 - val_accuracy: 0.7133\n",
            "Epoch 227/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2036 - accuracy: 0.9043 - val_loss: 2.8792 - val_accuracy: 0.7149\n",
            "Epoch 228/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2063 - accuracy: 0.9075 - val_loss: 3.4069 - val_accuracy: 0.7101\n",
            "Epoch 229/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2138 - accuracy: 0.9019 - val_loss: 3.0500 - val_accuracy: 0.7010\n",
            "Epoch 230/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1967 - accuracy: 0.9121 - val_loss: 3.0696 - val_accuracy: 0.7160\n",
            "Epoch 231/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2037 - accuracy: 0.9091 - val_loss: 2.8492 - val_accuracy: 0.7176\n",
            "Epoch 232/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2040 - accuracy: 0.9073 - val_loss: 3.5166 - val_accuracy: 0.6967\n",
            "Epoch 233/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1989 - accuracy: 0.9043 - val_loss: 3.3456 - val_accuracy: 0.7074\n",
            "Epoch 234/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2129 - accuracy: 0.9081 - val_loss: 2.5089 - val_accuracy: 0.7090\n",
            "Epoch 235/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1922 - accuracy: 0.9137 - val_loss: 3.1069 - val_accuracy: 0.7004\n",
            "Epoch 236/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1989 - accuracy: 0.9132 - val_loss: 3.1841 - val_accuracy: 0.7079\n",
            "Epoch 237/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1957 - accuracy: 0.9081 - val_loss: 3.3979 - val_accuracy: 0.7101\n",
            "Epoch 238/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1958 - accuracy: 0.9083 - val_loss: 3.5095 - val_accuracy: 0.7010\n",
            "Epoch 239/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2201 - accuracy: 0.9075 - val_loss: 2.4433 - val_accuracy: 0.7106\n",
            "Epoch 240/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1905 - accuracy: 0.9124 - val_loss: 3.6596 - val_accuracy: 0.7128\n",
            "Epoch 241/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1939 - accuracy: 0.9107 - val_loss: 2.8106 - val_accuracy: 0.6988\n",
            "Epoch 242/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1987 - accuracy: 0.9083 - val_loss: 3.2692 - val_accuracy: 0.7149\n",
            "Epoch 243/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1971 - accuracy: 0.9105 - val_loss: 3.1615 - val_accuracy: 0.7058\n",
            "Epoch 244/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1902 - accuracy: 0.9116 - val_loss: 3.4401 - val_accuracy: 0.7063\n",
            "Epoch 245/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2035 - accuracy: 0.9057 - val_loss: 3.1214 - val_accuracy: 0.7053\n",
            "Epoch 246/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1941 - accuracy: 0.9113 - val_loss: 3.8492 - val_accuracy: 0.7208\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 247/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1997 - accuracy: 0.9081 - val_loss: 3.7887 - val_accuracy: 0.7015\n",
            "Epoch 248/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1938 - accuracy: 0.9078 - val_loss: 3.1262 - val_accuracy: 0.7085\n",
            "Epoch 249/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1956 - accuracy: 0.9132 - val_loss: 3.2095 - val_accuracy: 0.7128\n",
            "Epoch 250/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2019 - accuracy: 0.9091 - val_loss: 2.9922 - val_accuracy: 0.7079\n",
            "Epoch 251/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2038 - accuracy: 0.9059 - val_loss: 3.4839 - val_accuracy: 0.7042\n",
            "Epoch 252/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1890 - accuracy: 0.9158 - val_loss: 3.2479 - val_accuracy: 0.7095\n",
            "Epoch 253/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1894 - accuracy: 0.9161 - val_loss: 3.9539 - val_accuracy: 0.7047\n",
            "Epoch 254/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2033 - accuracy: 0.9073 - val_loss: 2.7475 - val_accuracy: 0.6977\n",
            "Epoch 255/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1911 - accuracy: 0.9102 - val_loss: 3.0896 - val_accuracy: 0.7128\n",
            "Epoch 256/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1971 - accuracy: 0.9116 - val_loss: 3.5591 - val_accuracy: 0.6940\n",
            "Epoch 257/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2032 - accuracy: 0.9070 - val_loss: 2.7784 - val_accuracy: 0.7074\n",
            "Epoch 258/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1896 - accuracy: 0.9118 - val_loss: 3.7400 - val_accuracy: 0.7090\n",
            "Epoch 259/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1948 - accuracy: 0.9140 - val_loss: 3.9345 - val_accuracy: 0.7074\n",
            "Epoch 260/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1947 - accuracy: 0.9124 - val_loss: 3.5269 - val_accuracy: 0.7111\n",
            "Epoch 261/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1859 - accuracy: 0.9142 - val_loss: 3.5159 - val_accuracy: 0.6977\n",
            "Epoch 262/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1922 - accuracy: 0.9145 - val_loss: 4.5906 - val_accuracy: 0.7020\n",
            "Epoch 263/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1966 - accuracy: 0.9169 - val_loss: 3.1809 - val_accuracy: 0.7069\n",
            "Epoch 264/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1971 - accuracy: 0.9169 - val_loss: 2.7558 - val_accuracy: 0.7042\n",
            "Epoch 265/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1895 - accuracy: 0.9129 - val_loss: 2.9484 - val_accuracy: 0.7069\n",
            "Epoch 266/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1891 - accuracy: 0.9142 - val_loss: 2.8277 - val_accuracy: 0.7165\n",
            "Epoch 267/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1924 - accuracy: 0.9172 - val_loss: 3.1637 - val_accuracy: 0.6935\n",
            "Epoch 268/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1880 - accuracy: 0.9161 - val_loss: 3.1249 - val_accuracy: 0.7074\n",
            "Epoch 269/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1851 - accuracy: 0.9156 - val_loss: 3.3923 - val_accuracy: 0.7085\n",
            "Epoch 270/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1872 - accuracy: 0.9201 - val_loss: 3.0248 - val_accuracy: 0.7031\n",
            "Epoch 271/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1879 - accuracy: 0.9129 - val_loss: 3.0995 - val_accuracy: 0.7058\n",
            "Epoch 272/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1866 - accuracy: 0.9150 - val_loss: 3.7852 - val_accuracy: 0.7074\n",
            "Epoch 273/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1893 - accuracy: 0.9161 - val_loss: 3.5356 - val_accuracy: 0.7015\n",
            "Epoch 274/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1965 - accuracy: 0.9145 - val_loss: 2.9018 - val_accuracy: 0.6913\n",
            "Epoch 275/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1830 - accuracy: 0.9118 - val_loss: 3.8635 - val_accuracy: 0.7144\n",
            "Epoch 276/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1856 - accuracy: 0.9116 - val_loss: 2.9773 - val_accuracy: 0.6999\n",
            "Epoch 277/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1918 - accuracy: 0.9145 - val_loss: 3.2386 - val_accuracy: 0.7069\n",
            "Epoch 278/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1821 - accuracy: 0.9201 - val_loss: 3.0358 - val_accuracy: 0.7010\n",
            "Epoch 279/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1871 - accuracy: 0.9156 - val_loss: 3.3506 - val_accuracy: 0.7058\n",
            "Epoch 280/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1902 - accuracy: 0.9134 - val_loss: 4.1859 - val_accuracy: 0.7010\n",
            "Epoch 281/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1865 - accuracy: 0.9126 - val_loss: 3.7438 - val_accuracy: 0.7053\n",
            "Epoch 282/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1877 - accuracy: 0.9134 - val_loss: 3.1923 - val_accuracy: 0.7058\n",
            "Epoch 283/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1823 - accuracy: 0.9204 - val_loss: 2.9848 - val_accuracy: 0.7101\n",
            "Epoch 284/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1886 - accuracy: 0.9161 - val_loss: 3.5187 - val_accuracy: 0.7063\n",
            "Epoch 285/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1834 - accuracy: 0.9233 - val_loss: 2.9867 - val_accuracy: 0.7074\n",
            "Epoch 286/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1832 - accuracy: 0.9185 - val_loss: 3.3569 - val_accuracy: 0.7047\n",
            "Epoch 287/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1821 - accuracy: 0.9188 - val_loss: 3.4740 - val_accuracy: 0.6983\n",
            "Epoch 288/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1883 - accuracy: 0.9142 - val_loss: 2.9199 - val_accuracy: 0.7004\n",
            "Epoch 289/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2010 - accuracy: 0.9145 - val_loss: 3.4098 - val_accuracy: 0.6999\n",
            "Epoch 290/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1941 - accuracy: 0.9166 - val_loss: 3.1236 - val_accuracy: 0.6994\n",
            "Epoch 291/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1778 - accuracy: 0.9134 - val_loss: 4.4780 - val_accuracy: 0.7047\n",
            "Epoch 292/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1747 - accuracy: 0.9183 - val_loss: 2.9824 - val_accuracy: 0.7117\n",
            "Epoch 293/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1840 - accuracy: 0.9137 - val_loss: 3.2575 - val_accuracy: 0.6988\n",
            "Epoch 294/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1742 - accuracy: 0.9204 - val_loss: 3.5625 - val_accuracy: 0.7079\n",
            "Epoch 295/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1945 - accuracy: 0.9129 - val_loss: 3.9386 - val_accuracy: 0.7020\n",
            "Epoch 296/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1851 - accuracy: 0.9158 - val_loss: 3.9773 - val_accuracy: 0.7047\n",
            "Epoch 297/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1807 - accuracy: 0.9191 - val_loss: 4.3222 - val_accuracy: 0.7047\n",
            "Epoch 298/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1812 - accuracy: 0.9177 - val_loss: 3.4351 - val_accuracy: 0.7154\n",
            "Epoch 299/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1867 - accuracy: 0.9158 - val_loss: 3.5988 - val_accuracy: 0.7085\n",
            "Epoch 300/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.1729 - accuracy: 0.9233 - val_loss: 2.8052 - val_accuracy: 0.7111\n",
            "accuracy: 72.08%\n",
            "Train on 3731 samples, validate on 1866 samples\n",
            "Epoch 1/300\n",
            "3731/3731 [==============================] - 11s 3ms/step - loss: 0.8260 - accuracy: 0.5229 - val_loss: 0.8099 - val_accuracy: 0.5504\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 2/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.7876 - accuracy: 0.5358 - val_loss: 0.7751 - val_accuracy: 0.5504\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 3/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.7858 - accuracy: 0.5347 - val_loss: 0.7750 - val_accuracy: 0.5504\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 4/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.7828 - accuracy: 0.5452 - val_loss: 0.7758 - val_accuracy: 0.5504\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 5/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.7842 - accuracy: 0.5511 - val_loss: 0.7734 - val_accuracy: 0.5504\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 6/300\n",
            "3731/3731 [==============================] - 11s 3ms/step - loss: 0.7768 - accuracy: 0.5497 - val_loss: 0.7756 - val_accuracy: 0.5504\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 7/300\n",
            "3731/3731 [==============================] - 11s 3ms/step - loss: 0.7809 - accuracy: 0.5497 - val_loss: 0.7723 - val_accuracy: 0.5504\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 8/300\n",
            "3731/3731 [==============================] - 11s 3ms/step - loss: 0.7620 - accuracy: 0.5677 - val_loss: 0.6873 - val_accuracy: 0.6656\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 9/300\n",
            "3731/3731 [==============================] - 11s 3ms/step - loss: 0.7340 - accuracy: 0.5988 - val_loss: 0.7069 - val_accuracy: 0.6656\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 10/300\n",
            "3731/3731 [==============================] - 11s 3ms/step - loss: 0.7124 - accuracy: 0.6087 - val_loss: 0.7036 - val_accuracy: 0.5841\n",
            "Epoch 11/300\n",
            "3731/3731 [==============================] - 11s 3ms/step - loss: 0.6942 - accuracy: 0.6202 - val_loss: 0.6490 - val_accuracy: 0.6795\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 12/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.6753 - accuracy: 0.6438 - val_loss: 0.6418 - val_accuracy: 0.6838\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 13/300\n",
            "3731/3731 [==============================] - 11s 3ms/step - loss: 0.6727 - accuracy: 0.6355 - val_loss: 0.6574 - val_accuracy: 0.6736\n",
            "Epoch 14/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.6546 - accuracy: 0.6567 - val_loss: 0.6584 - val_accuracy: 0.6442\n",
            "Epoch 15/300\n",
            "3731/3731 [==============================] - 11s 3ms/step - loss: 0.6457 - accuracy: 0.6502 - val_loss: 0.6487 - val_accuracy: 0.6833\n",
            "Epoch 16/300\n",
            "3731/3731 [==============================] - 11s 3ms/step - loss: 0.6412 - accuracy: 0.6583 - val_loss: 0.6501 - val_accuracy: 0.6774\n",
            "Epoch 17/300\n",
            "3731/3731 [==============================] - 11s 3ms/step - loss: 0.6283 - accuracy: 0.6738 - val_loss: 0.6406 - val_accuracy: 0.6795\n",
            "Epoch 18/300\n",
            "3731/3731 [==============================] - 11s 3ms/step - loss: 0.6217 - accuracy: 0.6781 - val_loss: 0.7013 - val_accuracy: 0.6570\n",
            "Epoch 19/300\n",
            "3731/3731 [==============================] - 11s 3ms/step - loss: 0.6098 - accuracy: 0.6816 - val_loss: 0.6347 - val_accuracy: 0.6833\n",
            "Epoch 20/300\n",
            "3731/3731 [==============================] - 11s 3ms/step - loss: 0.5944 - accuracy: 0.6907 - val_loss: 0.7365 - val_accuracy: 0.6758\n",
            "Epoch 21/300\n",
            "3731/3731 [==============================] - 11s 3ms/step - loss: 0.5923 - accuracy: 0.7001 - val_loss: 0.6574 - val_accuracy: 0.6870\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 22/300\n",
            "3731/3731 [==============================] - 11s 3ms/step - loss: 0.5697 - accuracy: 0.7070 - val_loss: 0.6478 - val_accuracy: 0.6876\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 23/300\n",
            "3731/3731 [==============================] - 11s 3ms/step - loss: 0.5624 - accuracy: 0.7129 - val_loss: 0.6781 - val_accuracy: 0.6940\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 24/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.5621 - accuracy: 0.7097 - val_loss: 0.6366 - val_accuracy: 0.6951\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 25/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.5517 - accuracy: 0.7199 - val_loss: 0.6795 - val_accuracy: 0.6961\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 26/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.5448 - accuracy: 0.7274 - val_loss: 0.6629 - val_accuracy: 0.6838\n",
            "Epoch 27/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.5433 - accuracy: 0.7255 - val_loss: 0.6646 - val_accuracy: 0.6752\n",
            "Epoch 28/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.5374 - accuracy: 0.7285 - val_loss: 0.7231 - val_accuracy: 0.6726\n",
            "Epoch 29/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.5330 - accuracy: 0.7301 - val_loss: 0.7257 - val_accuracy: 0.6919\n",
            "Epoch 30/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.5301 - accuracy: 0.7322 - val_loss: 0.6665 - val_accuracy: 0.6897\n",
            "Epoch 31/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.5229 - accuracy: 0.7363 - val_loss: 0.6809 - val_accuracy: 0.6919\n",
            "Epoch 32/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.5199 - accuracy: 0.7322 - val_loss: 0.7237 - val_accuracy: 0.6929\n",
            "Epoch 33/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.5132 - accuracy: 0.7411 - val_loss: 0.7683 - val_accuracy: 0.6838\n",
            "Epoch 34/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.5030 - accuracy: 0.7389 - val_loss: 0.7439 - val_accuracy: 0.6999\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 35/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.5074 - accuracy: 0.7448 - val_loss: 0.7051 - val_accuracy: 0.6801\n",
            "Epoch 36/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.5051 - accuracy: 0.7427 - val_loss: 0.7224 - val_accuracy: 0.6945\n",
            "Epoch 37/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4965 - accuracy: 0.7403 - val_loss: 0.6962 - val_accuracy: 0.6951\n",
            "Epoch 38/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4935 - accuracy: 0.7553 - val_loss: 0.8150 - val_accuracy: 0.6983\n",
            "Epoch 39/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4914 - accuracy: 0.7435 - val_loss: 0.8130 - val_accuracy: 0.6935\n",
            "Epoch 40/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4937 - accuracy: 0.7427 - val_loss: 0.7617 - val_accuracy: 0.6994\n",
            "Epoch 41/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4891 - accuracy: 0.7505 - val_loss: 0.8799 - val_accuracy: 0.7015\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 42/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4894 - accuracy: 0.7507 - val_loss: 0.8581 - val_accuracy: 0.6945\n",
            "Epoch 43/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4829 - accuracy: 0.7572 - val_loss: 0.8031 - val_accuracy: 0.6897\n",
            "Epoch 44/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4796 - accuracy: 0.7531 - val_loss: 0.7977 - val_accuracy: 0.7053\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 45/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4786 - accuracy: 0.7534 - val_loss: 0.9218 - val_accuracy: 0.6988\n",
            "Epoch 46/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4822 - accuracy: 0.7569 - val_loss: 0.8813 - val_accuracy: 0.6886\n",
            "Epoch 47/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4720 - accuracy: 0.7531 - val_loss: 0.9306 - val_accuracy: 0.6913\n",
            "Epoch 48/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4733 - accuracy: 0.7529 - val_loss: 0.8508 - val_accuracy: 0.6983\n",
            "Epoch 49/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4730 - accuracy: 0.7529 - val_loss: 0.8786 - val_accuracy: 0.6994\n",
            "Epoch 50/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4678 - accuracy: 0.7623 - val_loss: 0.9167 - val_accuracy: 0.6972\n",
            "Epoch 51/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4664 - accuracy: 0.7609 - val_loss: 0.9042 - val_accuracy: 0.6977\n",
            "Epoch 52/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4665 - accuracy: 0.7628 - val_loss: 0.9023 - val_accuracy: 0.7004\n",
            "Epoch 53/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4582 - accuracy: 0.7668 - val_loss: 1.0597 - val_accuracy: 0.6994\n",
            "Epoch 54/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4588 - accuracy: 0.7577 - val_loss: 1.0579 - val_accuracy: 0.6951\n",
            "Epoch 55/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4561 - accuracy: 0.7703 - val_loss: 0.8683 - val_accuracy: 0.6972\n",
            "Epoch 56/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4571 - accuracy: 0.7649 - val_loss: 0.9370 - val_accuracy: 0.6844\n",
            "Epoch 57/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4554 - accuracy: 0.7711 - val_loss: 0.8891 - val_accuracy: 0.6983\n",
            "Epoch 58/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4553 - accuracy: 0.7639 - val_loss: 0.9798 - val_accuracy: 0.7004\n",
            "Epoch 59/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4530 - accuracy: 0.7676 - val_loss: 0.9466 - val_accuracy: 0.6961\n",
            "Epoch 60/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4521 - accuracy: 0.7655 - val_loss: 0.9839 - val_accuracy: 0.6967\n",
            "Epoch 61/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4554 - accuracy: 0.7676 - val_loss: 0.8652 - val_accuracy: 0.7085\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 62/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4530 - accuracy: 0.7698 - val_loss: 0.8568 - val_accuracy: 0.7026\n",
            "Epoch 63/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4470 - accuracy: 0.7703 - val_loss: 1.0277 - val_accuracy: 0.7101\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 64/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4480 - accuracy: 0.7730 - val_loss: 0.9813 - val_accuracy: 0.7015\n",
            "Epoch 65/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4503 - accuracy: 0.7722 - val_loss: 0.9726 - val_accuracy: 0.6892\n",
            "Epoch 66/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4468 - accuracy: 0.7749 - val_loss: 0.8363 - val_accuracy: 0.6999\n",
            "Epoch 67/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4455 - accuracy: 0.7698 - val_loss: 1.0127 - val_accuracy: 0.6977\n",
            "Epoch 68/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4422 - accuracy: 0.7695 - val_loss: 0.9662 - val_accuracy: 0.6956\n",
            "Epoch 69/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4489 - accuracy: 0.7692 - val_loss: 0.9493 - val_accuracy: 0.7063\n",
            "Epoch 70/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4440 - accuracy: 0.7703 - val_loss: 1.1218 - val_accuracy: 0.7053\n",
            "Epoch 71/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4416 - accuracy: 0.7711 - val_loss: 0.9406 - val_accuracy: 0.7015\n",
            "Epoch 72/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4401 - accuracy: 0.7706 - val_loss: 1.1053 - val_accuracy: 0.6961\n",
            "Epoch 73/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4436 - accuracy: 0.7738 - val_loss: 1.0141 - val_accuracy: 0.7058\n",
            "Epoch 74/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4379 - accuracy: 0.7754 - val_loss: 0.9147 - val_accuracy: 0.7010\n",
            "Epoch 75/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4410 - accuracy: 0.7770 - val_loss: 1.0003 - val_accuracy: 0.7053\n",
            "Epoch 76/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4369 - accuracy: 0.7770 - val_loss: 0.9135 - val_accuracy: 0.7031\n",
            "Epoch 77/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4388 - accuracy: 0.7794 - val_loss: 1.2850 - val_accuracy: 0.7031\n",
            "Epoch 78/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4374 - accuracy: 0.7749 - val_loss: 1.0832 - val_accuracy: 0.7015\n",
            "Epoch 79/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4372 - accuracy: 0.7757 - val_loss: 1.0008 - val_accuracy: 0.6961\n",
            "Epoch 80/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4324 - accuracy: 0.7765 - val_loss: 0.9828 - val_accuracy: 0.6988\n",
            "Epoch 81/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4340 - accuracy: 0.7813 - val_loss: 1.0544 - val_accuracy: 0.6940\n",
            "Epoch 82/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4329 - accuracy: 0.7781 - val_loss: 1.1261 - val_accuracy: 0.6999\n",
            "Epoch 83/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4396 - accuracy: 0.7767 - val_loss: 1.2938 - val_accuracy: 0.6977\n",
            "Epoch 84/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4370 - accuracy: 0.7754 - val_loss: 1.1729 - val_accuracy: 0.7101\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 85/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4270 - accuracy: 0.7840 - val_loss: 1.1016 - val_accuracy: 0.6972\n",
            "Epoch 86/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4365 - accuracy: 0.7759 - val_loss: 1.0804 - val_accuracy: 0.6956\n",
            "Epoch 87/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4346 - accuracy: 0.7719 - val_loss: 1.1555 - val_accuracy: 0.6935\n",
            "Epoch 88/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4243 - accuracy: 0.7794 - val_loss: 1.1165 - val_accuracy: 0.7031\n",
            "Epoch 89/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4297 - accuracy: 0.7775 - val_loss: 1.2735 - val_accuracy: 0.7053\n",
            "Epoch 90/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4288 - accuracy: 0.7808 - val_loss: 1.1634 - val_accuracy: 0.7069\n",
            "Epoch 91/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4270 - accuracy: 0.7775 - val_loss: 1.1380 - val_accuracy: 0.6988\n",
            "Epoch 92/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4306 - accuracy: 0.7767 - val_loss: 1.1321 - val_accuracy: 0.6999\n",
            "Epoch 93/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4239 - accuracy: 0.7837 - val_loss: 1.2263 - val_accuracy: 0.6967\n",
            "Epoch 94/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4266 - accuracy: 0.7837 - val_loss: 1.1771 - val_accuracy: 0.7004\n",
            "Epoch 95/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4233 - accuracy: 0.7797 - val_loss: 1.1288 - val_accuracy: 0.7004\n",
            "Epoch 96/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4253 - accuracy: 0.7781 - val_loss: 1.1265 - val_accuracy: 0.7026\n",
            "Epoch 97/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4235 - accuracy: 0.7797 - val_loss: 1.0875 - val_accuracy: 0.7004\n",
            "Epoch 98/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4222 - accuracy: 0.7845 - val_loss: 1.2193 - val_accuracy: 0.6919\n",
            "Epoch 99/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4197 - accuracy: 0.7875 - val_loss: 1.2674 - val_accuracy: 0.6951\n",
            "Epoch 100/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4207 - accuracy: 0.7904 - val_loss: 1.1328 - val_accuracy: 0.6940\n",
            "Epoch 101/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4214 - accuracy: 0.7834 - val_loss: 1.2060 - val_accuracy: 0.7004\n",
            "Epoch 102/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4202 - accuracy: 0.7834 - val_loss: 1.1163 - val_accuracy: 0.7010\n",
            "Epoch 103/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4179 - accuracy: 0.7853 - val_loss: 1.2152 - val_accuracy: 0.7020\n",
            "Epoch 104/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4220 - accuracy: 0.7824 - val_loss: 1.2042 - val_accuracy: 0.7036\n",
            "Epoch 105/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4163 - accuracy: 0.7872 - val_loss: 1.0819 - val_accuracy: 0.7042\n",
            "Epoch 106/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4181 - accuracy: 0.7840 - val_loss: 1.2040 - val_accuracy: 0.6999\n",
            "Epoch 107/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4152 - accuracy: 0.7912 - val_loss: 1.0735 - val_accuracy: 0.7015\n",
            "Epoch 108/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4172 - accuracy: 0.7832 - val_loss: 1.3314 - val_accuracy: 0.6935\n",
            "Epoch 109/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4137 - accuracy: 0.7832 - val_loss: 1.3431 - val_accuracy: 0.7015\n",
            "Epoch 110/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4129 - accuracy: 0.7920 - val_loss: 1.2546 - val_accuracy: 0.6967\n",
            "Epoch 111/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4144 - accuracy: 0.7880 - val_loss: 1.3823 - val_accuracy: 0.7010\n",
            "Epoch 112/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4158 - accuracy: 0.7888 - val_loss: 1.4370 - val_accuracy: 0.7111\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 113/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4124 - accuracy: 0.7850 - val_loss: 1.3770 - val_accuracy: 0.6935\n",
            "Epoch 114/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4121 - accuracy: 0.7867 - val_loss: 1.2368 - val_accuracy: 0.7095\n",
            "Epoch 115/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4180 - accuracy: 0.7875 - val_loss: 1.3194 - val_accuracy: 0.7004\n",
            "Epoch 116/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4074 - accuracy: 0.7901 - val_loss: 1.2402 - val_accuracy: 0.7020\n",
            "Epoch 117/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4082 - accuracy: 0.7915 - val_loss: 1.2826 - val_accuracy: 0.7015\n",
            "Epoch 118/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4096 - accuracy: 0.7901 - val_loss: 1.2401 - val_accuracy: 0.7031\n",
            "Epoch 119/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4055 - accuracy: 0.7885 - val_loss: 1.3020 - val_accuracy: 0.7176\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 120/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4085 - accuracy: 0.7896 - val_loss: 1.0446 - val_accuracy: 0.7042\n",
            "Epoch 121/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4014 - accuracy: 0.7928 - val_loss: 1.1664 - val_accuracy: 0.7111\n",
            "Epoch 122/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4028 - accuracy: 0.7966 - val_loss: 1.3981 - val_accuracy: 0.7122\n",
            "Epoch 123/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4031 - accuracy: 0.7971 - val_loss: 1.5233 - val_accuracy: 0.7004\n",
            "Epoch 124/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4108 - accuracy: 0.7917 - val_loss: 1.2349 - val_accuracy: 0.7036\n",
            "Epoch 125/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4018 - accuracy: 0.7982 - val_loss: 1.2781 - val_accuracy: 0.7128\n",
            "Epoch 126/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3965 - accuracy: 0.7995 - val_loss: 1.3939 - val_accuracy: 0.7063\n",
            "Epoch 127/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3977 - accuracy: 0.7987 - val_loss: 1.3843 - val_accuracy: 0.7031\n",
            "Epoch 128/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4014 - accuracy: 0.7950 - val_loss: 1.4611 - val_accuracy: 0.7106\n",
            "Epoch 129/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3990 - accuracy: 0.7992 - val_loss: 1.1697 - val_accuracy: 0.7042\n",
            "Epoch 130/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3975 - accuracy: 0.8009 - val_loss: 1.2866 - val_accuracy: 0.7042\n",
            "Epoch 131/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3902 - accuracy: 0.8006 - val_loss: 1.5014 - val_accuracy: 0.7181\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 132/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.4008 - accuracy: 0.8001 - val_loss: 1.2293 - val_accuracy: 0.7213\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 133/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3944 - accuracy: 0.8022 - val_loss: 1.2815 - val_accuracy: 0.7053\n",
            "Epoch 134/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3922 - accuracy: 0.7974 - val_loss: 1.2945 - val_accuracy: 0.7170\n",
            "Epoch 135/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3855 - accuracy: 0.8054 - val_loss: 1.3706 - val_accuracy: 0.7101\n",
            "Epoch 136/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3876 - accuracy: 0.8092 - val_loss: 1.2958 - val_accuracy: 0.7117\n",
            "Epoch 137/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3779 - accuracy: 0.8124 - val_loss: 1.3943 - val_accuracy: 0.7117\n",
            "Epoch 138/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3874 - accuracy: 0.8041 - val_loss: 1.2711 - val_accuracy: 0.7160\n",
            "Epoch 139/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3803 - accuracy: 0.8062 - val_loss: 1.3619 - val_accuracy: 0.7144\n",
            "Epoch 140/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3825 - accuracy: 0.8113 - val_loss: 1.2472 - val_accuracy: 0.7203\n",
            "Epoch 141/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3787 - accuracy: 0.8132 - val_loss: 1.5047 - val_accuracy: 0.7154\n",
            "Epoch 142/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3758 - accuracy: 0.8137 - val_loss: 1.4763 - val_accuracy: 0.7128\n",
            "Epoch 143/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3736 - accuracy: 0.8118 - val_loss: 1.3455 - val_accuracy: 0.6983\n",
            "Epoch 144/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3719 - accuracy: 0.8167 - val_loss: 1.3316 - val_accuracy: 0.7117\n",
            "Epoch 145/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3687 - accuracy: 0.8204 - val_loss: 1.3200 - val_accuracy: 0.7165\n",
            "Epoch 146/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3686 - accuracy: 0.8143 - val_loss: 1.5098 - val_accuracy: 0.7053\n",
            "Epoch 147/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3684 - accuracy: 0.8183 - val_loss: 1.3485 - val_accuracy: 0.7138\n",
            "Epoch 148/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3664 - accuracy: 0.8196 - val_loss: 1.5034 - val_accuracy: 0.7272\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 149/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3699 - accuracy: 0.8223 - val_loss: 1.8603 - val_accuracy: 0.7170\n",
            "Epoch 150/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3690 - accuracy: 0.8250 - val_loss: 1.6787 - val_accuracy: 0.7122\n",
            "Epoch 151/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3665 - accuracy: 0.8202 - val_loss: 1.5160 - val_accuracy: 0.6956\n",
            "Epoch 152/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3599 - accuracy: 0.8244 - val_loss: 1.4558 - val_accuracy: 0.7144\n",
            "Epoch 153/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3619 - accuracy: 0.8236 - val_loss: 1.5976 - val_accuracy: 0.7138\n",
            "Epoch 154/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3581 - accuracy: 0.8279 - val_loss: 1.4312 - val_accuracy: 0.7197\n",
            "Epoch 155/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3564 - accuracy: 0.8231 - val_loss: 1.6095 - val_accuracy: 0.7176\n",
            "Epoch 156/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3597 - accuracy: 0.8274 - val_loss: 1.5226 - val_accuracy: 0.7256\n",
            "Epoch 157/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3581 - accuracy: 0.8271 - val_loss: 1.5207 - val_accuracy: 0.7117\n",
            "Epoch 158/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3562 - accuracy: 0.8295 - val_loss: 1.4488 - val_accuracy: 0.7272\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 159/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3523 - accuracy: 0.8290 - val_loss: 1.4870 - val_accuracy: 0.7278\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 160/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3518 - accuracy: 0.8271 - val_loss: 1.9067 - val_accuracy: 0.7213\n",
            "Epoch 161/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3550 - accuracy: 0.8317 - val_loss: 1.7336 - val_accuracy: 0.7203\n",
            "Epoch 162/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3531 - accuracy: 0.8338 - val_loss: 1.4810 - val_accuracy: 0.7203\n",
            "Epoch 163/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3542 - accuracy: 0.8236 - val_loss: 1.8825 - val_accuracy: 0.7197\n",
            "Epoch 164/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3529 - accuracy: 0.8282 - val_loss: 1.5537 - val_accuracy: 0.7224\n",
            "Epoch 165/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3460 - accuracy: 0.8349 - val_loss: 1.7030 - val_accuracy: 0.7288\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 166/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3530 - accuracy: 0.8303 - val_loss: 1.6349 - val_accuracy: 0.7181\n",
            "Epoch 167/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3448 - accuracy: 0.8346 - val_loss: 1.7734 - val_accuracy: 0.7213\n",
            "Epoch 168/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3494 - accuracy: 0.8338 - val_loss: 1.6393 - val_accuracy: 0.7272\n",
            "Epoch 169/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3462 - accuracy: 0.8309 - val_loss: 1.5706 - val_accuracy: 0.7245\n",
            "Epoch 170/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3447 - accuracy: 0.8330 - val_loss: 1.3520 - val_accuracy: 0.7197\n",
            "Epoch 171/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3473 - accuracy: 0.8373 - val_loss: 1.5763 - val_accuracy: 0.7224\n",
            "Epoch 172/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3454 - accuracy: 0.8346 - val_loss: 1.3158 - val_accuracy: 0.7203\n",
            "Epoch 173/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3433 - accuracy: 0.8376 - val_loss: 1.4898 - val_accuracy: 0.7262\n",
            "Epoch 174/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3437 - accuracy: 0.8322 - val_loss: 1.6232 - val_accuracy: 0.7160\n",
            "Epoch 175/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3481 - accuracy: 0.8298 - val_loss: 2.0298 - val_accuracy: 0.7251\n",
            "Epoch 176/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3437 - accuracy: 0.8309 - val_loss: 2.0612 - val_accuracy: 0.7213\n",
            "Epoch 177/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3401 - accuracy: 0.8338 - val_loss: 1.4319 - val_accuracy: 0.7186\n",
            "Epoch 178/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3395 - accuracy: 0.8354 - val_loss: 1.5334 - val_accuracy: 0.7170\n",
            "Epoch 179/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3388 - accuracy: 0.8405 - val_loss: 1.8073 - val_accuracy: 0.7186\n",
            "Epoch 180/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3424 - accuracy: 0.8373 - val_loss: 1.3959 - val_accuracy: 0.7267\n",
            "Epoch 181/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3378 - accuracy: 0.8370 - val_loss: 1.8337 - val_accuracy: 0.7186\n",
            "Epoch 182/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3410 - accuracy: 0.8386 - val_loss: 1.9118 - val_accuracy: 0.7256\n",
            "Epoch 183/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3346 - accuracy: 0.8416 - val_loss: 2.1634 - val_accuracy: 0.7197\n",
            "Epoch 184/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3444 - accuracy: 0.8362 - val_loss: 1.5971 - val_accuracy: 0.7262\n",
            "Epoch 185/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3400 - accuracy: 0.8360 - val_loss: 1.6967 - val_accuracy: 0.7267\n",
            "Epoch 186/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3326 - accuracy: 0.8384 - val_loss: 1.7097 - val_accuracy: 0.7213\n",
            "Epoch 187/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3366 - accuracy: 0.8333 - val_loss: 2.0900 - val_accuracy: 0.7224\n",
            "Epoch 188/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3374 - accuracy: 0.8376 - val_loss: 2.4356 - val_accuracy: 0.6956\n",
            "Epoch 189/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3336 - accuracy: 0.8392 - val_loss: 1.9697 - val_accuracy: 0.7235\n",
            "Epoch 190/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3405 - accuracy: 0.8341 - val_loss: 1.5588 - val_accuracy: 0.7245\n",
            "Epoch 191/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3313 - accuracy: 0.8386 - val_loss: 1.6362 - val_accuracy: 0.7256\n",
            "Epoch 192/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3298 - accuracy: 0.8419 - val_loss: 2.0132 - val_accuracy: 0.7036\n",
            "Epoch 193/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3309 - accuracy: 0.8378 - val_loss: 2.0199 - val_accuracy: 0.7079\n",
            "Epoch 194/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3391 - accuracy: 0.8378 - val_loss: 1.8069 - val_accuracy: 0.7213\n",
            "Epoch 195/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3255 - accuracy: 0.8445 - val_loss: 2.3348 - val_accuracy: 0.7208\n",
            "Epoch 196/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3368 - accuracy: 0.8437 - val_loss: 1.8114 - val_accuracy: 0.7186\n",
            "Epoch 197/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3277 - accuracy: 0.8416 - val_loss: 2.1442 - val_accuracy: 0.7262\n",
            "Epoch 198/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3349 - accuracy: 0.8429 - val_loss: 1.5757 - val_accuracy: 0.7186\n",
            "Epoch 199/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3340 - accuracy: 0.8440 - val_loss: 1.9663 - val_accuracy: 0.7149\n",
            "Epoch 200/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3313 - accuracy: 0.8386 - val_loss: 1.4522 - val_accuracy: 0.7181\n",
            "Epoch 201/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3285 - accuracy: 0.8416 - val_loss: 1.8617 - val_accuracy: 0.7186\n",
            "Epoch 202/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3280 - accuracy: 0.8437 - val_loss: 1.9465 - val_accuracy: 0.7304\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 203/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3265 - accuracy: 0.8427 - val_loss: 2.4253 - val_accuracy: 0.7074\n",
            "Epoch 204/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3321 - accuracy: 0.8483 - val_loss: 2.0580 - val_accuracy: 0.7192\n",
            "Epoch 205/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3213 - accuracy: 0.8456 - val_loss: 1.8507 - val_accuracy: 0.7192\n",
            "Epoch 206/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3258 - accuracy: 0.8486 - val_loss: 1.6215 - val_accuracy: 0.7256\n",
            "Epoch 207/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3232 - accuracy: 0.8421 - val_loss: 2.0862 - val_accuracy: 0.7160\n",
            "Epoch 208/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3222 - accuracy: 0.8456 - val_loss: 2.2765 - val_accuracy: 0.7181\n",
            "Epoch 209/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3263 - accuracy: 0.8451 - val_loss: 1.7711 - val_accuracy: 0.7192\n",
            "Epoch 210/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3289 - accuracy: 0.8483 - val_loss: 1.8486 - val_accuracy: 0.7170\n",
            "Epoch 211/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3212 - accuracy: 0.8470 - val_loss: 1.5788 - val_accuracy: 0.7208\n",
            "Epoch 212/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3255 - accuracy: 0.8480 - val_loss: 1.8289 - val_accuracy: 0.7267\n",
            "Epoch 213/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3252 - accuracy: 0.8435 - val_loss: 1.8194 - val_accuracy: 0.7203\n",
            "Epoch 214/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3221 - accuracy: 0.8472 - val_loss: 1.5748 - val_accuracy: 0.7090\n",
            "Epoch 215/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3198 - accuracy: 0.8507 - val_loss: 1.6782 - val_accuracy: 0.7122\n",
            "Epoch 216/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3293 - accuracy: 0.8456 - val_loss: 1.9698 - val_accuracy: 0.7197\n",
            "Epoch 217/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3210 - accuracy: 0.8496 - val_loss: 1.9453 - val_accuracy: 0.7128\n",
            "Epoch 218/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3214 - accuracy: 0.8499 - val_loss: 2.0697 - val_accuracy: 0.7186\n",
            "Epoch 219/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3201 - accuracy: 0.8529 - val_loss: 1.8566 - val_accuracy: 0.7160\n",
            "Epoch 220/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3181 - accuracy: 0.8464 - val_loss: 1.7707 - val_accuracy: 0.7224\n",
            "Epoch 221/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3195 - accuracy: 0.8478 - val_loss: 1.6650 - val_accuracy: 0.7219\n",
            "Epoch 222/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3144 - accuracy: 0.8456 - val_loss: 1.8039 - val_accuracy: 0.7245\n",
            "Epoch 223/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3135 - accuracy: 0.8504 - val_loss: 2.2308 - val_accuracy: 0.7235\n",
            "Epoch 224/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3160 - accuracy: 0.8518 - val_loss: 1.6839 - val_accuracy: 0.7208\n",
            "Epoch 225/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3196 - accuracy: 0.8467 - val_loss: 1.5909 - val_accuracy: 0.7160\n",
            "Epoch 226/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3158 - accuracy: 0.8496 - val_loss: 1.5290 - val_accuracy: 0.7085\n",
            "Epoch 227/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3215 - accuracy: 0.8504 - val_loss: 2.0098 - val_accuracy: 0.7192\n",
            "Epoch 228/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3144 - accuracy: 0.8539 - val_loss: 2.1859 - val_accuracy: 0.7203\n",
            "Epoch 229/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3170 - accuracy: 0.8491 - val_loss: 2.5815 - val_accuracy: 0.7111\n",
            "Epoch 230/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3198 - accuracy: 0.8510 - val_loss: 2.0747 - val_accuracy: 0.7203\n",
            "Epoch 231/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3169 - accuracy: 0.8504 - val_loss: 2.0738 - val_accuracy: 0.7181\n",
            "Epoch 232/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3227 - accuracy: 0.8499 - val_loss: 1.6045 - val_accuracy: 0.7026\n",
            "Epoch 233/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3064 - accuracy: 0.8553 - val_loss: 1.5527 - val_accuracy: 0.7165\n",
            "Epoch 234/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3206 - accuracy: 0.8510 - val_loss: 2.0206 - val_accuracy: 0.7111\n",
            "Epoch 235/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3195 - accuracy: 0.8462 - val_loss: 1.9784 - val_accuracy: 0.7144\n",
            "Epoch 236/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3116 - accuracy: 0.8534 - val_loss: 1.8508 - val_accuracy: 0.7138\n",
            "Epoch 237/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3179 - accuracy: 0.8553 - val_loss: 2.0259 - val_accuracy: 0.7144\n",
            "Epoch 238/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3140 - accuracy: 0.8547 - val_loss: 1.8977 - val_accuracy: 0.7197\n",
            "Epoch 239/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3158 - accuracy: 0.8499 - val_loss: 1.9473 - val_accuracy: 0.7192\n",
            "Epoch 240/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3127 - accuracy: 0.8537 - val_loss: 2.2357 - val_accuracy: 0.7133\n",
            "Epoch 241/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3104 - accuracy: 0.8547 - val_loss: 2.2355 - val_accuracy: 0.7186\n",
            "Epoch 242/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3083 - accuracy: 0.8542 - val_loss: 2.5057 - val_accuracy: 0.7154\n",
            "Epoch 243/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3091 - accuracy: 0.8547 - val_loss: 2.2979 - val_accuracy: 0.7133\n",
            "Epoch 244/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3115 - accuracy: 0.8577 - val_loss: 2.5622 - val_accuracy: 0.7101\n",
            "Epoch 245/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3061 - accuracy: 0.8563 - val_loss: 2.2336 - val_accuracy: 0.7229\n",
            "Epoch 246/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3001 - accuracy: 0.8563 - val_loss: 2.5701 - val_accuracy: 0.7219\n",
            "Epoch 247/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3097 - accuracy: 0.8577 - val_loss: 1.8316 - val_accuracy: 0.7117\n",
            "Epoch 248/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3097 - accuracy: 0.8579 - val_loss: 2.5637 - val_accuracy: 0.7117\n",
            "Epoch 249/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3033 - accuracy: 0.8563 - val_loss: 2.3905 - val_accuracy: 0.7229\n",
            "Epoch 250/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3055 - accuracy: 0.8569 - val_loss: 2.3305 - val_accuracy: 0.7181\n",
            "Epoch 251/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3151 - accuracy: 0.8534 - val_loss: 1.8585 - val_accuracy: 0.7245\n",
            "Epoch 252/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3004 - accuracy: 0.8593 - val_loss: 1.9807 - val_accuracy: 0.7197\n",
            "Epoch 253/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3100 - accuracy: 0.8569 - val_loss: 2.4063 - val_accuracy: 0.7203\n",
            "Epoch 254/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3068 - accuracy: 0.8588 - val_loss: 2.0578 - val_accuracy: 0.7186\n",
            "Epoch 255/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3028 - accuracy: 0.8628 - val_loss: 2.0866 - val_accuracy: 0.7262\n",
            "Epoch 256/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2990 - accuracy: 0.8606 - val_loss: 2.3899 - val_accuracy: 0.7245\n",
            "Epoch 257/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3051 - accuracy: 0.8566 - val_loss: 2.1566 - val_accuracy: 0.7144\n",
            "Epoch 258/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3048 - accuracy: 0.8574 - val_loss: 1.9742 - val_accuracy: 0.7192\n",
            "Epoch 259/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3025 - accuracy: 0.8590 - val_loss: 2.7972 - val_accuracy: 0.7036\n",
            "Epoch 260/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3048 - accuracy: 0.8577 - val_loss: 1.6781 - val_accuracy: 0.7224\n",
            "Epoch 261/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3059 - accuracy: 0.8588 - val_loss: 2.1863 - val_accuracy: 0.7224\n",
            "Epoch 262/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2999 - accuracy: 0.8612 - val_loss: 2.2360 - val_accuracy: 0.7117\n",
            "Epoch 263/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3012 - accuracy: 0.8604 - val_loss: 2.5751 - val_accuracy: 0.7165\n",
            "Epoch 264/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2997 - accuracy: 0.8620 - val_loss: 2.2405 - val_accuracy: 0.7047\n",
            "Epoch 265/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3002 - accuracy: 0.8606 - val_loss: 2.6268 - val_accuracy: 0.7111\n",
            "Epoch 266/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2999 - accuracy: 0.8644 - val_loss: 2.3818 - val_accuracy: 0.7106\n",
            "Epoch 267/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3032 - accuracy: 0.8604 - val_loss: 2.1722 - val_accuracy: 0.7165\n",
            "Epoch 268/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2983 - accuracy: 0.8628 - val_loss: 2.6578 - val_accuracy: 0.7138\n",
            "Epoch 269/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3030 - accuracy: 0.8614 - val_loss: 2.3863 - val_accuracy: 0.7144\n",
            "Epoch 270/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3035 - accuracy: 0.8614 - val_loss: 2.2511 - val_accuracy: 0.7101\n",
            "Epoch 271/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2974 - accuracy: 0.8636 - val_loss: 2.0024 - val_accuracy: 0.7111\n",
            "Epoch 272/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2966 - accuracy: 0.8644 - val_loss: 2.7753 - val_accuracy: 0.7149\n",
            "Epoch 273/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3011 - accuracy: 0.8617 - val_loss: 2.9492 - val_accuracy: 0.7144\n",
            "Epoch 274/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3012 - accuracy: 0.8585 - val_loss: 1.9462 - val_accuracy: 0.7160\n",
            "Epoch 275/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2980 - accuracy: 0.8644 - val_loss: 2.1908 - val_accuracy: 0.7144\n",
            "Epoch 276/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2914 - accuracy: 0.8604 - val_loss: 2.4262 - val_accuracy: 0.7165\n",
            "Epoch 277/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3035 - accuracy: 0.8606 - val_loss: 2.0882 - val_accuracy: 0.7090\n",
            "Epoch 278/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2922 - accuracy: 0.8655 - val_loss: 2.5917 - val_accuracy: 0.7176\n",
            "Epoch 279/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2973 - accuracy: 0.8609 - val_loss: 2.4125 - val_accuracy: 0.7106\n",
            "Epoch 280/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2969 - accuracy: 0.8593 - val_loss: 2.4572 - val_accuracy: 0.7085\n",
            "Epoch 281/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2970 - accuracy: 0.8628 - val_loss: 2.4824 - val_accuracy: 0.7053\n",
            "Epoch 282/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2923 - accuracy: 0.8649 - val_loss: 2.3529 - val_accuracy: 0.7133\n",
            "Epoch 283/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2950 - accuracy: 0.8644 - val_loss: 2.6279 - val_accuracy: 0.7160\n",
            "Epoch 284/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2960 - accuracy: 0.8630 - val_loss: 2.4000 - val_accuracy: 0.7144\n",
            "Epoch 285/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2922 - accuracy: 0.8657 - val_loss: 2.5446 - val_accuracy: 0.7138\n",
            "Epoch 286/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.3005 - accuracy: 0.8636 - val_loss: 2.6242 - val_accuracy: 0.7128\n",
            "Epoch 287/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2911 - accuracy: 0.8652 - val_loss: 2.4232 - val_accuracy: 0.7138\n",
            "Epoch 288/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2918 - accuracy: 0.8646 - val_loss: 3.1152 - val_accuracy: 0.7133\n",
            "Epoch 289/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2914 - accuracy: 0.8673 - val_loss: 2.0004 - val_accuracy: 0.7101\n",
            "Epoch 290/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2909 - accuracy: 0.8649 - val_loss: 4.0413 - val_accuracy: 0.7203\n",
            "Epoch 291/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2933 - accuracy: 0.8657 - val_loss: 3.1512 - val_accuracy: 0.7122\n",
            "Epoch 292/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2943 - accuracy: 0.8644 - val_loss: 2.7833 - val_accuracy: 0.7197\n",
            "Epoch 293/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2910 - accuracy: 0.8660 - val_loss: 2.3131 - val_accuracy: 0.7229\n",
            "Epoch 294/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2967 - accuracy: 0.8673 - val_loss: 2.9017 - val_accuracy: 0.7176\n",
            "Epoch 295/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2876 - accuracy: 0.8713 - val_loss: 3.0551 - val_accuracy: 0.7256\n",
            "Epoch 296/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2944 - accuracy: 0.8638 - val_loss: 2.9991 - val_accuracy: 0.7111\n",
            "Epoch 297/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2839 - accuracy: 0.8692 - val_loss: 2.6133 - val_accuracy: 0.7063\n",
            "Epoch 298/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2889 - accuracy: 0.8687 - val_loss: 2.5840 - val_accuracy: 0.7138\n",
            "Epoch 299/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2909 - accuracy: 0.8671 - val_loss: 2.9164 - val_accuracy: 0.7240\n",
            "Epoch 300/300\n",
            "3731/3731 [==============================] - 10s 3ms/step - loss: 0.2873 - accuracy: 0.8692 - val_loss: 3.3673 - val_accuracy: 0.7213\n",
            "accuracy: 73.04%\n",
            "Train on 3732 samples, validate on 1865 samples\n",
            "Epoch 1/300\n",
            "3732/3732 [==============================] - 12s 3ms/step - loss: 0.8253 - accuracy: 0.5177 - val_loss: 0.7754 - val_accuracy: 0.5507\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 2/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.7823 - accuracy: 0.5450 - val_loss: 0.7756 - val_accuracy: 0.5507\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 3/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.7803 - accuracy: 0.5426 - val_loss: 0.7745 - val_accuracy: 0.5507\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 4/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.7849 - accuracy: 0.5506 - val_loss: 0.7754 - val_accuracy: 0.5507\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 5/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.7800 - accuracy: 0.5528 - val_loss: 0.7727 - val_accuracy: 0.5507\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 6/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.7785 - accuracy: 0.5501 - val_loss: 0.7739 - val_accuracy: 0.5507\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 7/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.7790 - accuracy: 0.5466 - val_loss: 0.7780 - val_accuracy: 0.5507\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 8/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.7754 - accuracy: 0.5528 - val_loss: 0.7731 - val_accuracy: 0.5507\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 9/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.7725 - accuracy: 0.5662 - val_loss: 0.7897 - val_accuracy: 0.5646\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 10/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.7411 - accuracy: 0.5807 - val_loss: 0.7602 - val_accuracy: 0.5700\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 11/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.7116 - accuracy: 0.6155 - val_loss: 0.7090 - val_accuracy: 0.6461\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 12/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.6887 - accuracy: 0.6375 - val_loss: 0.6868 - val_accuracy: 0.6214\n",
            "Epoch 13/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.6667 - accuracy: 0.6436 - val_loss: 0.7255 - val_accuracy: 0.6322\n",
            "Epoch 14/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.6586 - accuracy: 0.6573 - val_loss: 0.6957 - val_accuracy: 0.6499\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 15/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.6509 - accuracy: 0.6659 - val_loss: 0.7133 - val_accuracy: 0.6483\n",
            "Epoch 16/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.6402 - accuracy: 0.6659 - val_loss: 0.6801 - val_accuracy: 0.6536\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 17/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.6343 - accuracy: 0.6793 - val_loss: 0.6605 - val_accuracy: 0.6697\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 18/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.6214 - accuracy: 0.6919 - val_loss: 0.6834 - val_accuracy: 0.6697\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 19/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.6086 - accuracy: 0.6870 - val_loss: 0.6732 - val_accuracy: 0.6724\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 20/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.5923 - accuracy: 0.7015 - val_loss: 0.6464 - val_accuracy: 0.6794\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 21/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.5826 - accuracy: 0.7031 - val_loss: 0.6814 - val_accuracy: 0.6724\n",
            "Epoch 22/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.5794 - accuracy: 0.7098 - val_loss: 0.6996 - val_accuracy: 0.6472\n",
            "Epoch 23/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.5692 - accuracy: 0.7154 - val_loss: 0.6591 - val_accuracy: 0.6729\n",
            "Epoch 24/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.5590 - accuracy: 0.7168 - val_loss: 0.6473 - val_accuracy: 0.6847\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 25/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.5616 - accuracy: 0.7197 - val_loss: 0.6727 - val_accuracy: 0.6928\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 26/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.5477 - accuracy: 0.7286 - val_loss: 0.6541 - val_accuracy: 0.6767\n",
            "Epoch 27/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.5490 - accuracy: 0.7288 - val_loss: 0.6969 - val_accuracy: 0.6815\n",
            "Epoch 28/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.5404 - accuracy: 0.7278 - val_loss: 0.7292 - val_accuracy: 0.6917\n",
            "Epoch 29/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.5364 - accuracy: 0.7320 - val_loss: 0.6625 - val_accuracy: 0.6804\n",
            "Epoch 30/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.5297 - accuracy: 0.7363 - val_loss: 0.6790 - val_accuracy: 0.6928\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 31/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.5278 - accuracy: 0.7382 - val_loss: 0.8229 - val_accuracy: 0.6847\n",
            "Epoch 32/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.5229 - accuracy: 0.7465 - val_loss: 0.7522 - val_accuracy: 0.6869\n",
            "Epoch 33/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.5213 - accuracy: 0.7454 - val_loss: 0.6803 - val_accuracy: 0.6820\n",
            "Epoch 34/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.5140 - accuracy: 0.7449 - val_loss: 0.8002 - val_accuracy: 0.7003\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 35/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.5142 - accuracy: 0.7473 - val_loss: 0.7251 - val_accuracy: 0.6895\n",
            "Epoch 36/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.5057 - accuracy: 0.7497 - val_loss: 0.7823 - val_accuracy: 0.6912\n",
            "Epoch 37/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.5004 - accuracy: 0.7495 - val_loss: 0.8019 - val_accuracy: 0.6922\n",
            "Epoch 38/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4983 - accuracy: 0.7462 - val_loss: 0.7901 - val_accuracy: 0.6874\n",
            "Epoch 39/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4999 - accuracy: 0.7462 - val_loss: 0.8309 - val_accuracy: 0.6869\n",
            "Epoch 40/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4945 - accuracy: 0.7524 - val_loss: 0.7757 - val_accuracy: 0.6831\n",
            "Epoch 41/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4799 - accuracy: 0.7615 - val_loss: 0.9167 - val_accuracy: 0.6783\n",
            "Epoch 42/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4839 - accuracy: 0.7572 - val_loss: 0.7907 - val_accuracy: 0.6777\n",
            "Epoch 43/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4801 - accuracy: 0.7634 - val_loss: 0.8001 - val_accuracy: 0.6836\n",
            "Epoch 44/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4780 - accuracy: 0.7575 - val_loss: 0.7826 - val_accuracy: 0.6917\n",
            "Epoch 45/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4702 - accuracy: 0.7591 - val_loss: 0.8191 - val_accuracy: 0.6895\n",
            "Epoch 46/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4788 - accuracy: 0.7623 - val_loss: 0.7669 - val_accuracy: 0.6863\n",
            "Epoch 47/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4672 - accuracy: 0.7645 - val_loss: 0.9453 - val_accuracy: 0.6944\n",
            "Epoch 48/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4661 - accuracy: 0.7693 - val_loss: 0.8642 - val_accuracy: 0.6799\n",
            "Epoch 49/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4641 - accuracy: 0.7688 - val_loss: 0.9243 - val_accuracy: 0.6906\n",
            "Epoch 50/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4630 - accuracy: 0.7666 - val_loss: 0.8977 - val_accuracy: 0.6895\n",
            "Epoch 51/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4645 - accuracy: 0.7685 - val_loss: 0.8668 - val_accuracy: 0.6901\n",
            "Epoch 52/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4633 - accuracy: 0.7690 - val_loss: 0.8347 - val_accuracy: 0.6901\n",
            "Epoch 53/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4557 - accuracy: 0.7706 - val_loss: 0.9127 - val_accuracy: 0.6767\n",
            "Epoch 54/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4515 - accuracy: 0.7795 - val_loss: 0.9466 - val_accuracy: 0.6831\n",
            "Epoch 55/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4544 - accuracy: 0.7797 - val_loss: 0.9748 - val_accuracy: 0.6933\n",
            "Epoch 56/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4495 - accuracy: 0.7781 - val_loss: 0.9272 - val_accuracy: 0.6971\n",
            "Epoch 57/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4505 - accuracy: 0.7717 - val_loss: 1.0104 - val_accuracy: 0.6954\n",
            "Epoch 58/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4477 - accuracy: 0.7763 - val_loss: 0.9890 - val_accuracy: 0.6842\n",
            "Epoch 59/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4470 - accuracy: 0.7757 - val_loss: 0.8850 - val_accuracy: 0.6794\n",
            "Epoch 60/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4450 - accuracy: 0.7763 - val_loss: 1.0137 - val_accuracy: 0.6863\n",
            "Epoch 61/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4441 - accuracy: 0.7779 - val_loss: 0.9284 - val_accuracy: 0.6885\n",
            "Epoch 62/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4407 - accuracy: 0.7760 - val_loss: 1.0489 - val_accuracy: 0.6928\n",
            "Epoch 63/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4386 - accuracy: 0.7832 - val_loss: 0.9235 - val_accuracy: 0.6917\n",
            "Epoch 64/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4370 - accuracy: 0.7805 - val_loss: 0.9490 - val_accuracy: 0.6971\n",
            "Epoch 65/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4372 - accuracy: 0.7803 - val_loss: 0.9684 - val_accuracy: 0.7029\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 66/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4363 - accuracy: 0.7805 - val_loss: 1.1365 - val_accuracy: 0.6917\n",
            "Epoch 67/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4359 - accuracy: 0.7867 - val_loss: 1.0194 - val_accuracy: 0.6949\n",
            "Epoch 68/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4380 - accuracy: 0.7803 - val_loss: 1.1605 - val_accuracy: 0.7003\n",
            "Epoch 69/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4347 - accuracy: 0.7819 - val_loss: 0.9016 - val_accuracy: 0.6965\n",
            "Epoch 70/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4288 - accuracy: 0.7878 - val_loss: 1.0461 - val_accuracy: 0.7024\n",
            "Epoch 71/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4347 - accuracy: 0.7816 - val_loss: 1.0971 - val_accuracy: 0.6906\n",
            "Epoch 72/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4340 - accuracy: 0.7856 - val_loss: 0.8892 - val_accuracy: 0.6831\n",
            "Epoch 73/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4279 - accuracy: 0.7824 - val_loss: 1.0170 - val_accuracy: 0.6949\n",
            "Epoch 74/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4251 - accuracy: 0.7918 - val_loss: 1.1008 - val_accuracy: 0.7003\n",
            "Epoch 75/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4266 - accuracy: 0.7886 - val_loss: 1.1748 - val_accuracy: 0.6949\n",
            "Epoch 76/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4288 - accuracy: 0.7859 - val_loss: 1.0035 - val_accuracy: 0.6885\n",
            "Epoch 77/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4232 - accuracy: 0.7902 - val_loss: 1.2489 - val_accuracy: 0.6954\n",
            "Epoch 78/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4201 - accuracy: 0.7870 - val_loss: 1.1273 - val_accuracy: 0.6976\n",
            "Epoch 79/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4207 - accuracy: 0.7926 - val_loss: 1.0693 - val_accuracy: 0.6890\n",
            "Epoch 80/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4214 - accuracy: 0.7931 - val_loss: 1.1054 - val_accuracy: 0.6879\n",
            "Epoch 81/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4225 - accuracy: 0.7848 - val_loss: 1.2458 - val_accuracy: 0.6879\n",
            "Epoch 82/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4239 - accuracy: 0.7856 - val_loss: 1.0386 - val_accuracy: 0.6820\n",
            "Epoch 83/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4200 - accuracy: 0.7910 - val_loss: 1.1175 - val_accuracy: 0.6879\n",
            "Epoch 84/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4163 - accuracy: 0.7918 - val_loss: 1.0788 - val_accuracy: 0.6815\n",
            "Epoch 85/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4203 - accuracy: 0.7918 - val_loss: 1.1782 - val_accuracy: 0.6949\n",
            "Epoch 86/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4124 - accuracy: 0.7918 - val_loss: 1.1931 - val_accuracy: 0.6906\n",
            "Epoch 87/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4188 - accuracy: 0.7880 - val_loss: 1.1461 - val_accuracy: 0.6954\n",
            "Epoch 88/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4183 - accuracy: 0.7905 - val_loss: 0.9823 - val_accuracy: 0.6842\n",
            "Epoch 89/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4162 - accuracy: 0.7950 - val_loss: 1.2096 - val_accuracy: 0.6965\n",
            "Epoch 90/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4131 - accuracy: 0.7956 - val_loss: 1.2937 - val_accuracy: 0.6912\n",
            "Epoch 91/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4164 - accuracy: 0.7947 - val_loss: 1.3380 - val_accuracy: 0.6879\n",
            "Epoch 92/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4122 - accuracy: 0.7913 - val_loss: 1.2785 - val_accuracy: 0.6863\n",
            "Epoch 93/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4121 - accuracy: 0.7902 - val_loss: 1.4363 - val_accuracy: 0.6906\n",
            "Epoch 94/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4108 - accuracy: 0.7945 - val_loss: 1.3772 - val_accuracy: 0.6987\n",
            "Epoch 95/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4125 - accuracy: 0.7923 - val_loss: 1.2468 - val_accuracy: 0.6885\n",
            "Epoch 96/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4079 - accuracy: 0.7977 - val_loss: 1.3037 - val_accuracy: 0.6901\n",
            "Epoch 97/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4108 - accuracy: 0.7980 - val_loss: 1.3369 - val_accuracy: 0.6788\n",
            "Epoch 98/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4146 - accuracy: 0.7910 - val_loss: 1.2274 - val_accuracy: 0.6960\n",
            "Epoch 99/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4077 - accuracy: 0.8014 - val_loss: 1.2058 - val_accuracy: 0.6858\n",
            "Epoch 100/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4072 - accuracy: 0.7902 - val_loss: 1.2809 - val_accuracy: 0.6901\n",
            "Epoch 101/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4052 - accuracy: 0.7985 - val_loss: 1.4210 - val_accuracy: 0.6938\n",
            "Epoch 102/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4074 - accuracy: 0.7958 - val_loss: 1.5113 - val_accuracy: 0.6981\n",
            "Epoch 103/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4055 - accuracy: 0.7966 - val_loss: 1.5283 - val_accuracy: 0.6901\n",
            "Epoch 104/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4090 - accuracy: 0.7977 - val_loss: 1.1898 - val_accuracy: 0.6879\n",
            "Epoch 105/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4064 - accuracy: 0.7980 - val_loss: 1.4391 - val_accuracy: 0.6890\n",
            "Epoch 106/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4013 - accuracy: 0.7966 - val_loss: 1.5097 - val_accuracy: 0.6917\n",
            "Epoch 107/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4068 - accuracy: 0.7958 - val_loss: 1.4450 - val_accuracy: 0.6895\n",
            "Epoch 108/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4030 - accuracy: 0.7956 - val_loss: 1.4541 - val_accuracy: 0.6820\n",
            "Epoch 109/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4036 - accuracy: 0.7969 - val_loss: 1.2540 - val_accuracy: 0.6922\n",
            "Epoch 110/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4041 - accuracy: 0.7953 - val_loss: 1.3077 - val_accuracy: 0.6820\n",
            "Epoch 111/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4005 - accuracy: 0.7998 - val_loss: 1.4011 - val_accuracy: 0.6895\n",
            "Epoch 112/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.4004 - accuracy: 0.8025 - val_loss: 1.6879 - val_accuracy: 0.6858\n",
            "Epoch 113/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3971 - accuracy: 0.8001 - val_loss: 1.6479 - val_accuracy: 0.6938\n",
            "Epoch 114/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3970 - accuracy: 0.8039 - val_loss: 1.4761 - val_accuracy: 0.6858\n",
            "Epoch 115/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3983 - accuracy: 0.8057 - val_loss: 1.5224 - val_accuracy: 0.6917\n",
            "Epoch 116/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3929 - accuracy: 0.8106 - val_loss: 1.4231 - val_accuracy: 0.6954\n",
            "Epoch 117/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3978 - accuracy: 0.8108 - val_loss: 1.3422 - val_accuracy: 0.6890\n",
            "Epoch 118/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3972 - accuracy: 0.8047 - val_loss: 1.2844 - val_accuracy: 0.6971\n",
            "Epoch 119/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3902 - accuracy: 0.8063 - val_loss: 1.8848 - val_accuracy: 0.6836\n",
            "Epoch 120/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3906 - accuracy: 0.8103 - val_loss: 1.4523 - val_accuracy: 0.6965\n",
            "Epoch 121/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3949 - accuracy: 0.8124 - val_loss: 1.4435 - val_accuracy: 0.6842\n",
            "Epoch 122/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3844 - accuracy: 0.8108 - val_loss: 1.5822 - val_accuracy: 0.6842\n",
            "Epoch 123/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3877 - accuracy: 0.8084 - val_loss: 1.4279 - val_accuracy: 0.6858\n",
            "Epoch 124/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3843 - accuracy: 0.8100 - val_loss: 1.3005 - val_accuracy: 0.6885\n",
            "Epoch 125/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3836 - accuracy: 0.8071 - val_loss: 1.7119 - val_accuracy: 0.6815\n",
            "Epoch 126/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3841 - accuracy: 0.8132 - val_loss: 1.7795 - val_accuracy: 0.6906\n",
            "Epoch 127/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3862 - accuracy: 0.8143 - val_loss: 1.7330 - val_accuracy: 0.6944\n",
            "Epoch 128/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3787 - accuracy: 0.8197 - val_loss: 1.6149 - val_accuracy: 0.6928\n",
            "Epoch 129/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3806 - accuracy: 0.8183 - val_loss: 1.6660 - val_accuracy: 0.6949\n",
            "Epoch 130/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3764 - accuracy: 0.8207 - val_loss: 1.6333 - val_accuracy: 0.6949\n",
            "Epoch 131/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3742 - accuracy: 0.8199 - val_loss: 1.5514 - val_accuracy: 0.6928\n",
            "Epoch 132/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3777 - accuracy: 0.8170 - val_loss: 1.6259 - val_accuracy: 0.6901\n",
            "Epoch 133/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3767 - accuracy: 0.8202 - val_loss: 1.4913 - val_accuracy: 0.6997\n",
            "Epoch 134/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3707 - accuracy: 0.8226 - val_loss: 1.7936 - val_accuracy: 0.6901\n",
            "Epoch 135/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3758 - accuracy: 0.8213 - val_loss: 1.3934 - val_accuracy: 0.6992\n",
            "Epoch 136/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3692 - accuracy: 0.8221 - val_loss: 1.4630 - val_accuracy: 0.7046\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 137/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3686 - accuracy: 0.8261 - val_loss: 1.6386 - val_accuracy: 0.6922\n",
            "Epoch 138/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3700 - accuracy: 0.8226 - val_loss: 1.8803 - val_accuracy: 0.6949\n",
            "Epoch 139/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3699 - accuracy: 0.8232 - val_loss: 1.5225 - val_accuracy: 0.7046\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 140/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3657 - accuracy: 0.8240 - val_loss: 1.4539 - val_accuracy: 0.6981\n",
            "Epoch 141/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3670 - accuracy: 0.8304 - val_loss: 1.5118 - val_accuracy: 0.6912\n",
            "Epoch 142/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3670 - accuracy: 0.8253 - val_loss: 1.6524 - val_accuracy: 0.6997\n",
            "Epoch 143/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3614 - accuracy: 0.8277 - val_loss: 1.7276 - val_accuracy: 0.6944\n",
            "Epoch 144/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3733 - accuracy: 0.8272 - val_loss: 1.7049 - val_accuracy: 0.6997\n",
            "Epoch 145/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3584 - accuracy: 0.8341 - val_loss: 1.7317 - val_accuracy: 0.6938\n",
            "Epoch 146/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3607 - accuracy: 0.8307 - val_loss: 1.7103 - val_accuracy: 0.7046\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 147/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3625 - accuracy: 0.8336 - val_loss: 1.6109 - val_accuracy: 0.6928\n",
            "Epoch 148/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3608 - accuracy: 0.8296 - val_loss: 1.8126 - val_accuracy: 0.7088\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 149/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3575 - accuracy: 0.8277 - val_loss: 2.0218 - val_accuracy: 0.6922\n",
            "Epoch 150/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3561 - accuracy: 0.8312 - val_loss: 1.5435 - val_accuracy: 0.6853\n",
            "Epoch 151/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3632 - accuracy: 0.8282 - val_loss: 2.0146 - val_accuracy: 0.6954\n",
            "Epoch 152/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3594 - accuracy: 0.8298 - val_loss: 1.7143 - val_accuracy: 0.6912\n",
            "Epoch 153/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3522 - accuracy: 0.8355 - val_loss: 1.8675 - val_accuracy: 0.6804\n",
            "Epoch 154/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3575 - accuracy: 0.8325 - val_loss: 1.8697 - val_accuracy: 0.7003\n",
            "Epoch 155/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3533 - accuracy: 0.8341 - val_loss: 2.0000 - val_accuracy: 0.7051\n",
            "Epoch 156/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3544 - accuracy: 0.8360 - val_loss: 1.8661 - val_accuracy: 0.6976\n",
            "Epoch 157/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3543 - accuracy: 0.8392 - val_loss: 2.0312 - val_accuracy: 0.6922\n",
            "Epoch 158/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3520 - accuracy: 0.8360 - val_loss: 2.0072 - val_accuracy: 0.6992\n",
            "Epoch 159/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3512 - accuracy: 0.8333 - val_loss: 2.2430 - val_accuracy: 0.7024\n",
            "Epoch 160/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3552 - accuracy: 0.8371 - val_loss: 1.7301 - val_accuracy: 0.6971\n",
            "Epoch 161/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3540 - accuracy: 0.8309 - val_loss: 1.8394 - val_accuracy: 0.7019\n",
            "Epoch 162/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3518 - accuracy: 0.8344 - val_loss: 2.0163 - val_accuracy: 0.6912\n",
            "Epoch 163/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3490 - accuracy: 0.8339 - val_loss: 1.9276 - val_accuracy: 0.6981\n",
            "Epoch 164/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3483 - accuracy: 0.8365 - val_loss: 1.7144 - val_accuracy: 0.6901\n",
            "Epoch 165/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3444 - accuracy: 0.8387 - val_loss: 1.9988 - val_accuracy: 0.6944\n",
            "Epoch 166/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3410 - accuracy: 0.8390 - val_loss: 1.8092 - val_accuracy: 0.6847\n",
            "Epoch 167/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3452 - accuracy: 0.8363 - val_loss: 1.7699 - val_accuracy: 0.6901\n",
            "Epoch 168/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3392 - accuracy: 0.8416 - val_loss: 1.7912 - val_accuracy: 0.7029\n",
            "Epoch 169/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3464 - accuracy: 0.8363 - val_loss: 1.8498 - val_accuracy: 0.7072\n",
            "Epoch 170/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3478 - accuracy: 0.8360 - val_loss: 2.1389 - val_accuracy: 0.6928\n",
            "Epoch 171/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3410 - accuracy: 0.8382 - val_loss: 1.8042 - val_accuracy: 0.7046\n",
            "Epoch 172/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3456 - accuracy: 0.8352 - val_loss: 1.9630 - val_accuracy: 0.6965\n",
            "Epoch 173/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3345 - accuracy: 0.8481 - val_loss: 1.8520 - val_accuracy: 0.6933\n",
            "Epoch 174/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3415 - accuracy: 0.8331 - val_loss: 1.7979 - val_accuracy: 0.7078\n",
            "Epoch 175/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3412 - accuracy: 0.8403 - val_loss: 1.8308 - val_accuracy: 0.7094\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 176/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3457 - accuracy: 0.8379 - val_loss: 1.5586 - val_accuracy: 0.6847\n",
            "Epoch 177/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3344 - accuracy: 0.8430 - val_loss: 1.8262 - val_accuracy: 0.6965\n",
            "Epoch 178/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3355 - accuracy: 0.8398 - val_loss: 2.1778 - val_accuracy: 0.6799\n",
            "Epoch 179/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3360 - accuracy: 0.8441 - val_loss: 1.9073 - val_accuracy: 0.6976\n",
            "Epoch 180/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3367 - accuracy: 0.8430 - val_loss: 2.1310 - val_accuracy: 0.6858\n",
            "Epoch 181/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3291 - accuracy: 0.8457 - val_loss: 2.0585 - val_accuracy: 0.6944\n",
            "Epoch 182/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3354 - accuracy: 0.8395 - val_loss: 2.4337 - val_accuracy: 0.6917\n",
            "Epoch 183/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3336 - accuracy: 0.8454 - val_loss: 2.0944 - val_accuracy: 0.7040\n",
            "Epoch 184/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3296 - accuracy: 0.8516 - val_loss: 2.0946 - val_accuracy: 0.6895\n",
            "Epoch 185/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3300 - accuracy: 0.8510 - val_loss: 2.0260 - val_accuracy: 0.6981\n",
            "Epoch 186/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3206 - accuracy: 0.8494 - val_loss: 1.9993 - val_accuracy: 0.6965\n",
            "Epoch 187/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3305 - accuracy: 0.8416 - val_loss: 2.0083 - val_accuracy: 0.6949\n",
            "Epoch 188/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3220 - accuracy: 0.8545 - val_loss: 1.9957 - val_accuracy: 0.6874\n",
            "Epoch 189/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3259 - accuracy: 0.8489 - val_loss: 2.2772 - val_accuracy: 0.7067\n",
            "Epoch 190/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3225 - accuracy: 0.8459 - val_loss: 2.1060 - val_accuracy: 0.6954\n",
            "Epoch 191/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3237 - accuracy: 0.8513 - val_loss: 2.1076 - val_accuracy: 0.6938\n",
            "Epoch 192/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3241 - accuracy: 0.8470 - val_loss: 2.1667 - val_accuracy: 0.6965\n",
            "Epoch 193/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3220 - accuracy: 0.8521 - val_loss: 1.7893 - val_accuracy: 0.6895\n",
            "Epoch 194/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3167 - accuracy: 0.8529 - val_loss: 2.3504 - val_accuracy: 0.6960\n",
            "Epoch 195/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3194 - accuracy: 0.8516 - val_loss: 2.1011 - val_accuracy: 0.7029\n",
            "Epoch 196/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3191 - accuracy: 0.8505 - val_loss: 2.3020 - val_accuracy: 0.6901\n",
            "Epoch 197/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3178 - accuracy: 0.8526 - val_loss: 2.0692 - val_accuracy: 0.6960\n",
            "Epoch 198/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3163 - accuracy: 0.8534 - val_loss: 2.2061 - val_accuracy: 0.7046\n",
            "Epoch 199/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3125 - accuracy: 0.8505 - val_loss: 2.2420 - val_accuracy: 0.7137\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 200/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3164 - accuracy: 0.8532 - val_loss: 2.3839 - val_accuracy: 0.6965\n",
            "Epoch 201/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3170 - accuracy: 0.8524 - val_loss: 2.7542 - val_accuracy: 0.6949\n",
            "Epoch 202/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3121 - accuracy: 0.8532 - val_loss: 2.2574 - val_accuracy: 0.6987\n",
            "Epoch 203/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3185 - accuracy: 0.8497 - val_loss: 2.4175 - val_accuracy: 0.6960\n",
            "Epoch 204/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3130 - accuracy: 0.8529 - val_loss: 2.4438 - val_accuracy: 0.6912\n",
            "Epoch 205/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3098 - accuracy: 0.8580 - val_loss: 2.1870 - val_accuracy: 0.7051\n",
            "Epoch 206/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3049 - accuracy: 0.8588 - val_loss: 2.4103 - val_accuracy: 0.6890\n",
            "Epoch 207/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3144 - accuracy: 0.8588 - val_loss: 2.0757 - val_accuracy: 0.6912\n",
            "Epoch 208/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3083 - accuracy: 0.8601 - val_loss: 2.1332 - val_accuracy: 0.6906\n",
            "Epoch 209/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3024 - accuracy: 0.8644 - val_loss: 1.9930 - val_accuracy: 0.6933\n",
            "Epoch 210/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3023 - accuracy: 0.8604 - val_loss: 1.7189 - val_accuracy: 0.6928\n",
            "Epoch 211/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3058 - accuracy: 0.8572 - val_loss: 2.2845 - val_accuracy: 0.6922\n",
            "Epoch 212/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3071 - accuracy: 0.8561 - val_loss: 2.4394 - val_accuracy: 0.7008\n",
            "Epoch 213/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2960 - accuracy: 0.8663 - val_loss: 2.3147 - val_accuracy: 0.7003\n",
            "Epoch 214/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3008 - accuracy: 0.8585 - val_loss: 2.3262 - val_accuracy: 0.6901\n",
            "Epoch 215/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3064 - accuracy: 0.8585 - val_loss: 2.2459 - val_accuracy: 0.6772\n",
            "Epoch 216/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3037 - accuracy: 0.8585 - val_loss: 2.6850 - val_accuracy: 0.6879\n",
            "Epoch 217/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2974 - accuracy: 0.8580 - val_loss: 2.1286 - val_accuracy: 0.7046\n",
            "Epoch 218/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3009 - accuracy: 0.8596 - val_loss: 2.6855 - val_accuracy: 0.7056\n",
            "Epoch 219/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2925 - accuracy: 0.8641 - val_loss: 2.0429 - val_accuracy: 0.7078\n",
            "Epoch 220/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2909 - accuracy: 0.8639 - val_loss: 1.7628 - val_accuracy: 0.6938\n",
            "Epoch 221/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.3073 - accuracy: 0.8623 - val_loss: 2.2441 - val_accuracy: 0.6949\n",
            "Epoch 222/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2907 - accuracy: 0.8682 - val_loss: 2.4071 - val_accuracy: 0.6960\n",
            "Epoch 223/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2910 - accuracy: 0.8647 - val_loss: 2.4135 - val_accuracy: 0.7029\n",
            "Epoch 224/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2894 - accuracy: 0.8620 - val_loss: 2.1068 - val_accuracy: 0.6992\n",
            "Epoch 225/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2913 - accuracy: 0.8655 - val_loss: 2.5355 - val_accuracy: 0.7019\n",
            "Epoch 226/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2972 - accuracy: 0.8625 - val_loss: 2.1077 - val_accuracy: 0.6987\n",
            "Epoch 227/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2857 - accuracy: 0.8612 - val_loss: 2.2208 - val_accuracy: 0.6954\n",
            "Epoch 228/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2879 - accuracy: 0.8644 - val_loss: 3.2152 - val_accuracy: 0.6944\n",
            "Epoch 229/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2871 - accuracy: 0.8714 - val_loss: 2.9031 - val_accuracy: 0.6938\n",
            "Epoch 230/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2738 - accuracy: 0.8698 - val_loss: 2.8131 - val_accuracy: 0.7008\n",
            "Epoch 231/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2895 - accuracy: 0.8692 - val_loss: 2.6119 - val_accuracy: 0.7024\n",
            "Epoch 232/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2824 - accuracy: 0.8676 - val_loss: 2.2687 - val_accuracy: 0.6987\n",
            "Epoch 233/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2883 - accuracy: 0.8695 - val_loss: 2.7133 - val_accuracy: 0.6949\n",
            "Epoch 234/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2817 - accuracy: 0.8706 - val_loss: 2.5139 - val_accuracy: 0.6981\n",
            "Epoch 235/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2766 - accuracy: 0.8708 - val_loss: 2.8913 - val_accuracy: 0.6960\n",
            "Epoch 236/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2803 - accuracy: 0.8700 - val_loss: 2.4989 - val_accuracy: 0.7035\n",
            "Epoch 237/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2684 - accuracy: 0.8749 - val_loss: 2.8843 - val_accuracy: 0.7046\n",
            "Epoch 238/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2778 - accuracy: 0.8762 - val_loss: 2.7019 - val_accuracy: 0.7051\n",
            "Epoch 239/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2777 - accuracy: 0.8730 - val_loss: 2.6476 - val_accuracy: 0.6992\n",
            "Epoch 240/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2880 - accuracy: 0.8765 - val_loss: 2.4575 - val_accuracy: 0.7046\n",
            "Epoch 241/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2684 - accuracy: 0.8773 - val_loss: 2.8085 - val_accuracy: 0.7040\n",
            "Epoch 242/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2700 - accuracy: 0.8759 - val_loss: 2.9634 - val_accuracy: 0.6992\n",
            "Epoch 243/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2824 - accuracy: 0.8735 - val_loss: 2.0549 - val_accuracy: 0.7008\n",
            "Epoch 244/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2745 - accuracy: 0.8730 - val_loss: 3.5557 - val_accuracy: 0.7088\n",
            "Epoch 245/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2755 - accuracy: 0.8792 - val_loss: 2.8906 - val_accuracy: 0.6976\n",
            "Epoch 246/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2716 - accuracy: 0.8808 - val_loss: 2.7153 - val_accuracy: 0.6965\n",
            "Epoch 247/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2676 - accuracy: 0.8767 - val_loss: 2.6732 - val_accuracy: 0.7013\n",
            "Epoch 248/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2653 - accuracy: 0.8767 - val_loss: 2.3604 - val_accuracy: 0.7029\n",
            "Epoch 249/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2601 - accuracy: 0.8845 - val_loss: 2.6051 - val_accuracy: 0.7051\n",
            "Epoch 250/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2653 - accuracy: 0.8757 - val_loss: 3.0675 - val_accuracy: 0.7013\n",
            "Epoch 251/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2610 - accuracy: 0.8754 - val_loss: 3.8765 - val_accuracy: 0.6928\n",
            "Epoch 252/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2699 - accuracy: 0.8805 - val_loss: 3.4254 - val_accuracy: 0.7040\n",
            "Epoch 253/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2587 - accuracy: 0.8800 - val_loss: 2.9649 - val_accuracy: 0.6960\n",
            "Epoch 254/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2583 - accuracy: 0.8810 - val_loss: 3.0266 - val_accuracy: 0.7003\n",
            "Epoch 255/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2610 - accuracy: 0.8810 - val_loss: 2.7214 - val_accuracy: 0.7013\n",
            "Epoch 256/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2577 - accuracy: 0.8845 - val_loss: 2.4199 - val_accuracy: 0.7019\n",
            "Epoch 257/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2537 - accuracy: 0.8875 - val_loss: 2.9010 - val_accuracy: 0.7024\n",
            "Epoch 258/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2581 - accuracy: 0.8832 - val_loss: 3.0110 - val_accuracy: 0.6949\n",
            "Epoch 259/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2555 - accuracy: 0.8842 - val_loss: 2.8586 - val_accuracy: 0.6949\n",
            "Epoch 260/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2527 - accuracy: 0.8877 - val_loss: 2.9719 - val_accuracy: 0.7062\n",
            "Epoch 261/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2561 - accuracy: 0.8842 - val_loss: 3.0419 - val_accuracy: 0.7040\n",
            "Epoch 262/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2647 - accuracy: 0.8813 - val_loss: 2.9962 - val_accuracy: 0.7062\n",
            "Epoch 263/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2479 - accuracy: 0.8885 - val_loss: 3.0587 - val_accuracy: 0.7013\n",
            "Epoch 264/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2631 - accuracy: 0.8896 - val_loss: 3.0510 - val_accuracy: 0.7126\n",
            "Epoch 265/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2648 - accuracy: 0.8837 - val_loss: 2.5542 - val_accuracy: 0.7072\n",
            "Epoch 266/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2460 - accuracy: 0.8872 - val_loss: 2.9397 - val_accuracy: 0.6997\n",
            "Epoch 267/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2463 - accuracy: 0.8880 - val_loss: 3.4287 - val_accuracy: 0.7019\n",
            "Epoch 268/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2492 - accuracy: 0.8915 - val_loss: 2.9858 - val_accuracy: 0.7024\n",
            "Epoch 269/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2511 - accuracy: 0.8816 - val_loss: 2.6512 - val_accuracy: 0.7180\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 270/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2546 - accuracy: 0.8856 - val_loss: 2.8450 - val_accuracy: 0.7078\n",
            "Epoch 271/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2425 - accuracy: 0.8926 - val_loss: 2.9570 - val_accuracy: 0.7126\n",
            "Epoch 272/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2516 - accuracy: 0.8883 - val_loss: 3.5809 - val_accuracy: 0.7040\n",
            "Epoch 273/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2447 - accuracy: 0.8885 - val_loss: 3.0078 - val_accuracy: 0.7035\n",
            "Epoch 274/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2489 - accuracy: 0.8872 - val_loss: 2.6507 - val_accuracy: 0.7099\n",
            "Epoch 275/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2404 - accuracy: 0.8942 - val_loss: 3.3217 - val_accuracy: 0.7040\n",
            "Epoch 276/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2444 - accuracy: 0.8920 - val_loss: 3.0611 - val_accuracy: 0.7040\n",
            "Epoch 277/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2422 - accuracy: 0.8893 - val_loss: 2.6808 - val_accuracy: 0.7040\n",
            "Epoch 278/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2452 - accuracy: 0.8888 - val_loss: 2.6744 - val_accuracy: 0.6879\n",
            "Epoch 279/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2393 - accuracy: 0.8899 - val_loss: 3.4938 - val_accuracy: 0.7024\n",
            "Epoch 280/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2327 - accuracy: 0.8939 - val_loss: 2.6581 - val_accuracy: 0.6944\n",
            "Epoch 281/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2489 - accuracy: 0.8912 - val_loss: 2.5365 - val_accuracy: 0.7046\n",
            "Epoch 282/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2346 - accuracy: 0.8934 - val_loss: 3.1377 - val_accuracy: 0.7094\n",
            "Epoch 283/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2409 - accuracy: 0.8920 - val_loss: 3.8332 - val_accuracy: 0.7008\n",
            "Epoch 284/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2281 - accuracy: 0.9009 - val_loss: 3.2924 - val_accuracy: 0.7013\n",
            "Epoch 285/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2390 - accuracy: 0.8963 - val_loss: 3.2713 - val_accuracy: 0.7153\n",
            "Epoch 286/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2291 - accuracy: 0.9003 - val_loss: 3.5596 - val_accuracy: 0.7051\n",
            "Epoch 287/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2272 - accuracy: 0.9041 - val_loss: 3.6600 - val_accuracy: 0.7223\n",
            "Validation Accuracy has improved. Saving Model.\n",
            "Epoch 288/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2278 - accuracy: 0.9017 - val_loss: 3.6005 - val_accuracy: 0.7008\n",
            "Epoch 289/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2324 - accuracy: 0.8979 - val_loss: 3.0440 - val_accuracy: 0.7040\n",
            "Epoch 290/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2446 - accuracy: 0.8992 - val_loss: 3.1631 - val_accuracy: 0.7126\n",
            "Epoch 291/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2279 - accuracy: 0.9038 - val_loss: 3.6181 - val_accuracy: 0.7078\n",
            "Epoch 292/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2341 - accuracy: 0.9017 - val_loss: 3.2847 - val_accuracy: 0.7217\n",
            "Epoch 293/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2294 - accuracy: 0.9014 - val_loss: 3.5025 - val_accuracy: 0.7115\n",
            "Epoch 294/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2283 - accuracy: 0.9001 - val_loss: 3.2418 - val_accuracy: 0.7126\n",
            "Epoch 295/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2278 - accuracy: 0.9011 - val_loss: 3.6937 - val_accuracy: 0.7121\n",
            "Epoch 296/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2273 - accuracy: 0.9065 - val_loss: 3.2710 - val_accuracy: 0.7072\n",
            "Epoch 297/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2243 - accuracy: 0.9038 - val_loss: 3.1021 - val_accuracy: 0.7056\n",
            "Epoch 298/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2285 - accuracy: 0.8998 - val_loss: 3.2800 - val_accuracy: 0.7142\n",
            "Epoch 299/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2210 - accuracy: 0.9006 - val_loss: 3.3433 - val_accuracy: 0.7137\n",
            "Epoch 300/300\n",
            "3732/3732 [==============================] - 10s 3ms/step - loss: 0.2291 - accuracy: 0.9035 - val_loss: 3.0638 - val_accuracy: 0.7067\n",
            "accuracy: 72.23%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5T66mzC0WD_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "e8e0c937-c8e1-4d14-ccdd-9085158b0d07"
      },
      "source": [
        "for i in range(0, len(cvscores)):\n",
        "  print(f'> Fold {i+1}: Validation Accuracy = {cvscores[i]}%')\n",
        "\n",
        "print(f'\\nAverage Validation Accuracy: {np.mean(cvscores)}')\n",
        "print(f'Variance: {np.std(cvscores)}')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> Fold 1: Validation Accuracy = 72.07931280136108%\n",
            "> Fold 2: Validation Accuracy = 73.04394245147705%\n",
            "> Fold 3: Validation Accuracy = 72.22520112991333%\n",
            "\n",
            "Average Validation Accuracy: 72.44948546091716\n",
            "Variance: 0.42454303772494656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkvFwSeoZptC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Y_pred = best_model.predict(x_val)\n",
        "# y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "# print('Confusion Matrix - Test')\n",
        "# y_val2 = np.argmax(y_val, axis=1)\n",
        "\n",
        "# print(confusion_matrix(y_val2, y_pred))\n",
        "# print('Classification Report')\n",
        "# target_names = ['Apr-May', 'Jan-Feb', 'Mar']\n",
        "# print(classification_report(y_val2, y_pred, target_names=target_names))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE7iFhbnZuEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Y_pred2 = best_model.predict(x_train)\n",
        "# y_pred2 = np.argmax(Y_pred2, axis=1)\n",
        "\n",
        "# print('Confusion Matrix - Train')\n",
        "# y_train2 = np.argmax(y_train, axis=1)\n",
        "\n",
        "# print(confusion_matrix(y_train2, y_pred2))\n",
        "# print('Classification Report')\n",
        "# target_names = ['Apr-May', 'Jan-Feb', 'Mar']\n",
        "# print(classification_report(y_train2, y_pred2, target_names=target_names))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4foMQBU6bu_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}