{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio.SeqIO import parse\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_contents = pd.read_csv(\"sequences.csv\")\n",
    "fasta_file = open(\"sequences.fasta\")\n",
    "records = parse(fasta_file,\"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we find the rows in the **sequences.csv** file, which have the entry in the **accession** column in common with the record id of the records in the fasta file, and we create a new column **Sequence** in the original dataframe filling them with the sequences in the records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in records:\n",
    "    cc = 0\n",
    "    for index, row in csv_contents.iterrows():\n",
    "        if row['Accession'] == str(record.id):\n",
    "            csv_contents.at[cc, 'Sequence'] = str(record.seq)\n",
    "            break\n",
    "        cc += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can delete those entries which have **NA** in the Sequence column in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_contents = csv_contents[csv_contents.Sequence != 'NA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a peek at the different columns and their corresponding *data types* and number of *non-null* entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1206 entries, 0 to 1205\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Accession         1206 non-null   object \n",
      " 1   Release_Date      1206 non-null   object \n",
      " 2   Species           1206 non-null   object \n",
      " 3   Length            1205 non-null   float64\n",
      " 4   Geo_Location      1203 non-null   object \n",
      " 5   Host              1204 non-null   object \n",
      " 6   Isolation_Source  337 non-null    object \n",
      " 7   Collection_Date   1205 non-null   object \n",
      " 8   Sequence          1205 non-null   object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 94.2+ KB\n"
     ]
    }
   ],
   "source": [
    "csv_contents.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the Regular expression `^USA.*` to find all those entries in the `Geo_Location` columns whose values match the given pattern, and remove all the other rows having **Geo_Location** column values not matching the given pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accession</th>\n",
       "      <th>Release_Date</th>\n",
       "      <th>Species</th>\n",
       "      <th>Length</th>\n",
       "      <th>Geo_Location</th>\n",
       "      <th>Host</th>\n",
       "      <th>Isolation_Source</th>\n",
       "      <th>Collection_Date</th>\n",
       "      <th>Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MT358401</td>\n",
       "      <td>2020-04-20T00:00:00Z</td>\n",
       "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
       "      <td>29895.0</td>\n",
       "      <td>USA: New Orleans, LA</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>oronasopharynx</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>TTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTTGT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MT358402</td>\n",
       "      <td>2020-04-20T00:00:00Z</td>\n",
       "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
       "      <td>29896.0</td>\n",
       "      <td>USA: New Orleans, LA</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>oronasopharynx</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>GTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTTG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MT358644</td>\n",
       "      <td>2020-04-20T00:00:00Z</td>\n",
       "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
       "      <td>29842.0</td>\n",
       "      <td>USA: WA</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>TAACAATCCTTTCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MT358645</td>\n",
       "      <td>2020-04-20T00:00:00Z</td>\n",
       "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
       "      <td>29831.0</td>\n",
       "      <td>USA: WA</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>CCTTTCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAACTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MT358646</td>\n",
       "      <td>2020-04-20T00:00:00Z</td>\n",
       "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
       "      <td>29862.0</td>\n",
       "      <td>USA: WA</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>TAAAGGTTTATACCTTCCCAGGTAACAAACCAATCAACTTTCGATC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MT358647</td>\n",
       "      <td>2020-04-20T00:00:00Z</td>\n",
       "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
       "      <td>29872.0</td>\n",
       "      <td>USA: WA</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>TNAAGGTTTATACCTTCCCAGGTAACAAACCTTTCAACTTTCGATC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MT358648</td>\n",
       "      <td>2020-04-20T00:00:00Z</td>\n",
       "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
       "      <td>29831.0</td>\n",
       "      <td>USA: WA</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>CCTTTCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAACTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MT358649</td>\n",
       "      <td>2020-04-20T00:00:00Z</td>\n",
       "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
       "      <td>29902.0</td>\n",
       "      <td>USA: WA</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>TTNAAGGTTTACACCTTCCCAGGTAACAAACCNTTHAACTTTCGAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MT358650</td>\n",
       "      <td>2020-04-20T00:00:00Z</td>\n",
       "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
       "      <td>29829.0</td>\n",
       "      <td>USA: WA</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>ACCTTTCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAACT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MT358651</td>\n",
       "      <td>2020-04-20T00:00:00Z</td>\n",
       "      <td>Severe acute respiratory syndrome-related coro...</td>\n",
       "      <td>29841.0</td>\n",
       "      <td>USA: CT</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>AACCAATCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAAC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accession          Release_Date  \\\n",
       "10  MT358401  2020-04-20T00:00:00Z   \n",
       "11  MT358402  2020-04-20T00:00:00Z   \n",
       "13  MT358644  2020-04-20T00:00:00Z   \n",
       "14  MT358645  2020-04-20T00:00:00Z   \n",
       "15  MT358646  2020-04-20T00:00:00Z   \n",
       "16  MT358647  2020-04-20T00:00:00Z   \n",
       "17  MT358648  2020-04-20T00:00:00Z   \n",
       "18  MT358649  2020-04-20T00:00:00Z   \n",
       "19  MT358650  2020-04-20T00:00:00Z   \n",
       "20  MT358651  2020-04-20T00:00:00Z   \n",
       "\n",
       "                                              Species   Length  \\\n",
       "10  Severe acute respiratory syndrome-related coro...  29895.0   \n",
       "11  Severe acute respiratory syndrome-related coro...  29896.0   \n",
       "13  Severe acute respiratory syndrome-related coro...  29842.0   \n",
       "14  Severe acute respiratory syndrome-related coro...  29831.0   \n",
       "15  Severe acute respiratory syndrome-related coro...  29862.0   \n",
       "16  Severe acute respiratory syndrome-related coro...  29872.0   \n",
       "17  Severe acute respiratory syndrome-related coro...  29831.0   \n",
       "18  Severe acute respiratory syndrome-related coro...  29902.0   \n",
       "19  Severe acute respiratory syndrome-related coro...  29829.0   \n",
       "20  Severe acute respiratory syndrome-related coro...  29841.0   \n",
       "\n",
       "            Geo_Location          Host Isolation_Source Collection_Date  \\\n",
       "10  USA: New Orleans, LA  Homo sapiens   oronasopharynx      2020-04-06   \n",
       "11  USA: New Orleans, LA  Homo sapiens   oronasopharynx      2020-04-06   \n",
       "13               USA: WA  Homo sapiens              NaN      2020-04-01   \n",
       "14               USA: WA  Homo sapiens              NaN      2020-03-31   \n",
       "15               USA: WA  Homo sapiens              NaN      2020-03-31   \n",
       "16               USA: WA  Homo sapiens              NaN      2020-03-31   \n",
       "17               USA: WA  Homo sapiens              NaN      2020-03-31   \n",
       "18               USA: WA  Homo sapiens              NaN      2020-03-31   \n",
       "19               USA: WA  Homo sapiens              NaN      2020-03-31   \n",
       "20               USA: CT  Homo sapiens              NaN      2020-03-30   \n",
       "\n",
       "                                             Sequence  \n",
       "10  TTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTTGT...  \n",
       "11  GTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTTG...  \n",
       "13  TAACAATCCTTTCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAA...  \n",
       "14  CCTTTCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAACTT...  \n",
       "15  TAAAGGTTTATACCTTCCCAGGTAACAAACCAATCAACTTTCGATC...  \n",
       "16  TNAAGGTTTATACCTTCCCAGGTAACAAACCTTTCAACTTTCGATC...  \n",
       "17  CCTTTCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAACTT...  \n",
       "18  TTNAAGGTTTACACCTTCCCAGGTAACAAACCNTTHAACTTTCGAT...  \n",
       "19  ACCTTTCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAACT...  \n",
       "20  AACCAATCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAAC...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern= \"^USA.*\"\n",
    "filter = csv_contents['Geo_Location'].str.contains(pattern,na=False)\n",
    "csv_contents = csv_contents[filter]\n",
    "csv_contents.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally writing the altered dataframe into a **final.csv** file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_contents.to_csv('final.csv',encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = csv_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check presence of **null** values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accession           False\n",
       "Release_Date        False\n",
       "Species             False\n",
       "Length              False\n",
       "Geo_Location        False\n",
       "Host                 True\n",
       "Isolation_Source     True\n",
       "Collection_Date     False\n",
       "Sequence            False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(df).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geo_Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Geo_Location\"].fillna(\"NA\", inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of Unique **Geo_Locations** in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Geo_Location'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of Datapoints for each **Geo_Location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USA: WA                      452\n",
      "USA                          201\n",
      "USA: VA                       58\n",
      "USA: UT                       54\n",
      "USA: ID                       28\n",
      "USA: MA                       19\n",
      "USA: CT                       18\n",
      "USA: GA                       15\n",
      "USA: CA                       10\n",
      "USA: IL                        9\n",
      "USA: PA                        9\n",
      "USA: MI                        9\n",
      "USA: FL                        8\n",
      "USA: MN                        8\n",
      "USA: AZ                        7\n",
      "USA: IA                        7\n",
      "USA: NC                        7\n",
      "USA: San Francisco, CA         7\n",
      "USA: SC                        7\n",
      "USA: TX                        5\n",
      "USA: NH                        4\n",
      "USA: IN                        4\n",
      "USA: OR                        4\n",
      "USA: RI                        4\n",
      "USA: OH                        3\n",
      "USA: NJ                        2\n",
      "USA: New Orleans, LA           2\n",
      "USA: NE                        2\n",
      "USA: NY                        2\n",
      "USA: NV                        2\n",
      "USA: MD                        2\n",
      "USA: HI                        2\n",
      "USA: DC                        1\n",
      "USA: Snohomish County, WA      1\n",
      "USA: WI                        1\n",
      "USA: Illinois                  1\n",
      "USA: KS                        1\n",
      "USA: MO                        1\n",
      "USA: North Carolina            1\n",
      "USA: CA, San Diego County      1\n",
      "USA: LA                        1\n",
      "Name: Geo_Location, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(df['Geo_Location'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Release_Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of Unique **Release_Dates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Release_Date'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of Datapoints for each **Release Date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-13T00:00:00Z    250\n",
      "2020-04-16T00:00:00Z    111\n",
      "2020-03-31T00:00:00Z    110\n",
      "2020-04-20T00:00:00Z    107\n",
      "2020-04-06T00:00:00Z     72\n",
      "2020-03-30T00:00:00Z     60\n",
      "2020-04-14T00:00:00Z     52\n",
      "2020-03-26T00:00:00Z     44\n",
      "2020-04-17T00:00:00Z     40\n",
      "2020-04-11T00:00:00Z     31\n",
      "2020-03-09T00:00:00Z     18\n",
      "2020-04-07T00:00:00Z     16\n",
      "2020-04-08T00:00:00Z     12\n",
      "2020-04-03T00:00:00Z      9\n",
      "2020-03-27T00:00:00Z      9\n",
      "2020-03-12T00:00:00Z      7\n",
      "2020-03-10T00:00:00Z      6\n",
      "2020-04-15T00:00:00Z      3\n",
      "2020-02-07T00:00:00Z      3\n",
      "2020-02-24T00:00:00Z      3\n",
      "2020-01-28T00:00:00Z      3\n",
      "2020-03-13T00:00:00Z      3\n",
      "2020-02-12T00:00:00Z      2\n",
      "2020-02-05T00:00:00Z      2\n",
      "2020-02-11T00:00:00Z      2\n",
      "2020-01-24T00:00:00Z      1\n",
      "2020-01-25T00:00:00Z      1\n",
      "2020-03-16T00:00:00Z      1\n",
      "2020-03-05T00:00:00Z      1\n",
      "2020-02-27T00:00:00Z      1\n",
      "Name: Release_Date, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(df['Release_Date'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
