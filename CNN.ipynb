{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "kWoHF3eJXeWg",
    "outputId": "26da04dc-5210-4871-f73c-9e60e1dcddaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "IMXmQWEdr54Z",
    "outputId": "a92d8d2f-2952-4247-c81b-23255128c452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting biopython\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/66/134dbd5f885fc71493c61b6cf04c9ea08082da28da5ed07709b02857cbd0/biopython-1.77-cp36-cp36m-manylinux1_x86_64.whl (2.3MB)\n",
      "\r",
      "\u001b[K     |▏                               | 10kB 23.5MB/s eta 0:00:01\r",
      "\u001b[K     |▎                               | 20kB 28.7MB/s eta 0:00:01\r",
      "\u001b[K     |▍                               | 30kB 33.3MB/s eta 0:00:01\r",
      "\u001b[K     |▋                               | 40kB 25.6MB/s eta 0:00:01\r",
      "\u001b[K     |▊                               | 51kB 14.9MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 61kB 13.7MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 71kB 13.3MB/s eta 0:00:01\r",
      "\u001b[K     |█▏                              | 81kB 14.4MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 92kB 12.1MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 102kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█▋                              | 112kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 122kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█▉                              | 133kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 143kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██▏                             | 153kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 163kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██▌                             | 174kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 184kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██▊                             | 194kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 204kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 215kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███▏                            | 225kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 235kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 245kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 256kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███▊                            | 266kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 276kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 286kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 296kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████▍                           | 307kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████▌                           | 317kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 327kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 337kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 348kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 358kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 368kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████▍                          | 378kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 389kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 399kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 409kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 419kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 430kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 440kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████▍                         | 450kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 460kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 471kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 481kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 491kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 501kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 512kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████▍                        | 522kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████▌                        | 532kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 542kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 552kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 563kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 573kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 583kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 593kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 604kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 614kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████▉                       | 624kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 634kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 645kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 655kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 665kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 675kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 686kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 696kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 706kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 716kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 727kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 737kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 747kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▊                     | 757kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 768kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 778kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 788kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 798kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▍                    | 808kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 819kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 829kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 839kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 849kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 860kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 870kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 880kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 890kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 901kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 911kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 921kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 931kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 942kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 952kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 962kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 972kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 983kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 993kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 1.0MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 1.0MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 1.0MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 1.0MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 1.0MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▉                 | 1.1MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 1.1MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 1.1MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 1.1MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▌                | 1.1MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 1.1MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 1.1MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 1.1MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 1.1MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 1.1MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 1.2MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 1.2MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 1.2MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 1.2MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 1.2MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 1.2MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▏              | 1.2MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 1.2MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 1.2MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▋              | 1.2MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▊              | 1.3MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 1.3MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 1.3MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▏             | 1.3MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▍             | 1.3MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 1.3MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 1.3MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▉             | 1.3MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 1.3MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 1.4MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 1.4MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 1.4MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▌            | 1.4MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 1.4MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▉            | 1.4MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 1.4MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 1.4MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 1.4MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 1.4MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 1.5MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▋           | 1.5MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 1.5MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 1.5MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 1.5MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 1.5MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▍          | 1.5MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▌          | 1.5MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 1.5MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 1.5MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 1.6MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▏         | 1.6MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 1.6MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▍         | 1.6MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▌         | 1.6MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▊         | 1.6MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 1.6MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 1.6MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▏        | 1.6MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 1.6MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 1.7MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 1.7MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▊        | 1.7MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 1.7MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 1.7MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▏       | 1.7MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 1.7MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▍       | 1.7MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 1.7MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 1.8MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 1.8MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 1.8MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 1.8MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▎      | 1.8MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 1.8MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 1.8MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▊      | 1.8MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 1.8MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 1.8MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 1.9MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▎     | 1.9MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 1.9MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 1.9MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 1.9MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 1.9MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 1.9MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▏    | 1.9MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 1.9MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 1.9MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▋    | 2.0MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 2.0MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 2.0MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 2.0MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 2.0MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▎   | 2.0MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 2.0MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 2.0MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▊   | 2.0MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 2.0MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 2.1MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 2.1MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 2.1MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 2.1MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 2.1MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 2.1MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 2.1MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 2.1MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 2.1MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 2.2MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 2.2MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▋ | 2.2MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 2.2MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 2.2MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 2.2MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 2.2MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 2.2MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 2.2MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 2.2MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 2.3MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 2.3MB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 2.3MB 12.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from biopython) (1.18.5)\n",
      "Installing collected packages: biopython\n",
      "Successfully installed biopython-1.77\n"
     ]
    }
   ],
   "source": [
    "!pip install biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rjrlYH4iXDxC",
    "outputId": "862b0a3f-b9bf-483e-a175-f3a6c8703bc1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio.SeqIO import parse\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "import keras\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, LeakyReLU\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from collections import Counter\n",
    "from sklearn.utils import class_weight\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DjQJiovXXDxM"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/drive/My Drive/WA_removed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sz7A9VZCXDxX"
   },
   "outputs": [],
   "source": [
    "def string_to_array(my_string):\n",
    "    my_string = my_string.lower()\n",
    "    my_string = re.sub('[^acgt]', 'z', my_string)\n",
    "    my_array = np.array(list(my_string))\n",
    "    return my_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "otoHagIgXDxe",
    "outputId": "0b278b0e-103b-433c-e2f2-2522e60c902e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(np.array(['a','c','g','t','z']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MH8w1VSRXDxl"
   },
   "outputs": [],
   "source": [
    "def ordinal_encoder(my_array):\n",
    "    \n",
    "    integer_encoded = label_encoder.transform(my_array)\n",
    "    float_encoded = integer_encoded.astype(float)\n",
    "    float_encoded[float_encoded == 0] = 0.25 # A\n",
    "    float_encoded[float_encoded == 1] = 0.50 # C\n",
    "    float_encoded[float_encoded == 2] = 0.75 # G\n",
    "    float_encoded[float_encoded == 3] = 1.00 # T\n",
    "    float_encoded[float_encoded == 4] = 0.00 # anything else, z\n",
    "    \n",
    "    return float_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "colab_type": "code",
    "id": "mhb-cZleXDxs",
    "outputId": "f043c421-1453-4a2e-8f4d-3f376ff6c4d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_seq</th>\n",
       "      <th>Geo_Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.75, 0.75, 1.0, 1.0, 1.0, 0.25, 1.0, 0.25, 0...</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.25, 1.0, 0.25, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5...</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.25, 0.25, 0.75, 0.75, 1.0, 1.0, 1.0, 0.25, ...</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.75, 0.75, 1.0, 0.25, 0.25, 0.5, 0.25, 0.25,...</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.75, 0.5, 1.0, 1.0, 0.25, 0.5, 0.75, 0.75, 1...</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5592</th>\n",
       "      <td>[0.25, 1.0, 1.0, 0.25, 0.25, 0.25, 0.75, 0.75,...</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5593</th>\n",
       "      <td>[0.25, 1.0, 1.0, 0.25, 0.25, 0.25, 0.75, 0.75,...</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5594</th>\n",
       "      <td>[0.25, 1.0, 1.0, 0.25, 0.25, 0.25, 0.75, 0.75,...</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5595</th>\n",
       "      <td>[0.25, 1.0, 1.0, 0.25, 0.25, 0.25, 0.75, 0.75,...</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5596</th>\n",
       "      <td>[0.25, 1.0, 1.0, 0.25, 0.25, 0.25, 0.75, 0.75,...</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5597 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                enc_seq Geo_Location\n",
       "0     [0.75, 0.75, 1.0, 1.0, 1.0, 0.25, 1.0, 0.25, 0...          USA\n",
       "1     [0.25, 1.0, 0.25, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5...          USA\n",
       "2     [0.25, 0.25, 0.75, 0.75, 1.0, 1.0, 1.0, 0.25, ...          USA\n",
       "3     [0.75, 0.75, 1.0, 0.25, 0.25, 0.5, 0.25, 0.25,...          USA\n",
       "4     [0.75, 0.5, 1.0, 1.0, 0.25, 0.5, 0.75, 0.75, 1...          USA\n",
       "...                                                 ...          ...\n",
       "5592  [0.25, 1.0, 1.0, 0.25, 0.25, 0.25, 0.75, 0.75,...   California\n",
       "5593  [0.25, 1.0, 1.0, 0.25, 0.25, 0.25, 0.75, 0.75,...   California\n",
       "5594  [0.25, 1.0, 1.0, 0.25, 0.25, 0.25, 0.75, 0.75,...       Others\n",
       "5595  [0.25, 1.0, 1.0, 0.25, 0.25, 0.25, 0.75, 0.75,...       Others\n",
       "5596  [0.25, 1.0, 1.0, 0.25, 0.25, 0.25, 0.75, 0.75,...          USA\n",
       "\n",
       "[5597 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=df[[\"Sequence\",\"Geo_Location\"]]\n",
    "data=data[data[\"Sequence\"].notna()]\n",
    "\n",
    "dummy=[]\n",
    "dum=np.array(dummy)\n",
    "\n",
    "form={\"inp_seq\":dum}\n",
    "\n",
    "seq_df = pd.DataFrame (form, columns = ['inp_seq'])\n",
    "\n",
    "seq_list=[]\n",
    "\n",
    "for idx, seq in enumerate(list(data[\"Sequence\"])):\n",
    "    arr=ordinal_encoder(string_to_array(seq))\n",
    "    seq_list.append(arr)\n",
    "    \n",
    "seq_df[\"inp_seq\"]=seq_list\n",
    "\n",
    "final_data= data.assign(enc_seq=seq_df)\n",
    "\n",
    "final_data=final_data[[\"enc_seq\",\"Geo_Location\"]]\n",
    "\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w8tt8sE-XDxz"
   },
   "outputs": [],
   "source": [
    "def get_maxLen(enc_seq):\n",
    "    \n",
    "    max=0\n",
    "    for row in enc_seq:\n",
    "        #print(type(row))\n",
    "        if(len(row)>max):\n",
    "            max=len(row)\n",
    "    \n",
    "    \n",
    "    return max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CrjHM7nUXDx3"
   },
   "outputs": [],
   "source": [
    "def append_arr(enc_seq, max_len):\n",
    "    \n",
    "    seq_l=list(enc_seq)\n",
    "    for i in range(len(seq_l),max_len):\n",
    "        seq_l.append(0)\n",
    "        \n",
    "    new_seq_ar=np.array(seq_l)\n",
    "\n",
    "        \n",
    "    return new_seq_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "Br8ums-2XDx7",
    "outputId": "ce24d6ea-07ac-498d-956c-0eb0be0e8323"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len is 29921\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>padded_enc_seq</th>\n",
       "      <th>Geo_Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.75, 0.75, 1.0, 1.0, 1.0, 0.25, 1.0, 0.25, 0...</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.25, 1.0, 0.25, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5...</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.25, 0.25, 0.75, 0.75, 1.0, 1.0, 1.0, 0.25, ...</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.75, 0.75, 1.0, 0.25, 0.25, 0.5, 0.25, 0.25,...</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.75, 0.5, 1.0, 1.0, 0.25, 0.5, 0.75, 0.75, 1...</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      padded_enc_seq Geo_Location\n",
       "0  [0.75, 0.75, 1.0, 1.0, 1.0, 0.25, 1.0, 0.25, 0...          USA\n",
       "1  [0.25, 1.0, 0.25, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5...          USA\n",
       "2  [0.25, 0.25, 0.75, 0.75, 1.0, 1.0, 1.0, 0.25, ...          USA\n",
       "3  [0.75, 0.75, 1.0, 0.25, 0.25, 0.5, 0.25, 0.25,...          USA\n",
       "4  [0.75, 0.5, 1.0, 1.0, 0.25, 0.5, 0.75, 0.75, 1...          USA"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "max_len=get_maxLen(final_data[\"enc_seq\"])\n",
    "print(\"max_len is\",max_len)\n",
    "if max_len%2 !=0:\n",
    "    max_len += 1\n",
    "\n",
    "n = 1\n",
    "for i in range(1, math.floor(math.sqrt(max_len))):\n",
    "    if max_len%i==0:\n",
    "        n = i\n",
    "\n",
    "padded_seq_list=[]\n",
    "\n",
    "for index, row in final_data.iterrows():\n",
    "    seq_ar=append_arr(row[\"enc_seq\"],max_len)\n",
    "    padded_seq_list.append(seq_ar)\n",
    "\n",
    "dummy=[]\n",
    "dum=np.array(dummy)\n",
    "form={\"padded_enc_seq\":dum}\n",
    "padded_seq_df = pd.DataFrame (form, columns = ['padded_enc_seq'])\n",
    "\n",
    "padded_seq_df[\"padded_enc_seq\"]=padded_seq_list\n",
    "\n",
    "padded_final_data= final_data.assign(padded_enc_seq=padded_seq_df)\n",
    "\n",
    "padded_final_data=padded_final_data[[\"padded_enc_seq\",\"Geo_Location\"]]\n",
    "\n",
    "padded_final_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MTnqbUsqXDyB"
   },
   "outputs": [],
   "source": [
    "def reshape_seq(seq, m ,n):\n",
    "    \n",
    "    r_seq=np.reshape(seq,(m,n))\n",
    "    \n",
    "    return r_seq\n",
    "\n",
    "re_seqList=[]\n",
    "\n",
    "for index, row in padded_final_data.iterrows():\n",
    "    seq_ar=reshape_seq(row[\"padded_enc_seq\"],n,max_len//n)\n",
    "    re_seqList.append(seq_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RfTmmQqXXDyG",
    "outputId": "0ec11f40-9350-4122-8df1-4e43a4050b4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5597, 6, 4987, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.asarray(re_seqList)\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2], 1))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eVdMOloCXDyM",
    "outputId": "4ece338f-bca9-4edf-e140-a037efa3578d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5597,)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = padded_final_data['Geo_Location'].values\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TPGwIk5SXDyR"
   },
   "outputs": [],
   "source": [
    "loc_classes = list(Y)\n",
    "loc_classes = np.array(loc_classes) \n",
    "loc_classes = list(np.unique(loc_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iGR_1qKlXDyX",
    "outputId": "78d0eead-f3ca-42af-c502-e3f39e166560"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5597,)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = padded_final_data['Geo_Location'].apply(loc_classes.index)\n",
    "Y = df.values\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "g5QHcwrgthc4",
    "outputId": "887c74fe-c210-4605-a8d2-6ce393431a9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-metrics\n",
      "  Downloading https://files.pythonhosted.org/packages/32/c9/a87420da8e73de944e63a8e9cdcfb1f03ca31a7c4cdcdbd45d2cdf13275a/keras_metrics-1.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.6/dist-packages (from keras-metrics) (2.3.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (3.13)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.0.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.18.5)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.1.2)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.4.1)\n",
      "Installing collected packages: keras-metrics\n",
      "Successfully installed keras-metrics-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4GGn1MbYXDyc"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras_metrics\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, LeakyReLU\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from collections import Counter\n",
    "from sklearn.utils import class_weight\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pVA5EwfHXDyi"
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "3ovoA3TUXDyl",
    "outputId": "9a36f85d-36bb-4e8c-ff33-038a0fba41d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X Shape: (3917, 6, 4987, 1)\n",
      "Train Y Shape: (3917,)\n",
      "Validation X Shape: (1680, 6, 4987, 1)\n",
      "Validation Y Shape: (1680,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train X Shape:\",x_train.shape)\n",
    "print(\"Train Y Shape:\",y_train.shape)\n",
    "print(\"Validation X Shape:\",x_val.shape)\n",
    "print(\"Validation Y Shape:\",y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "BWGFPxAsXDyq",
    "outputId": "ce17cf2d-8dd8-4e4e-90fe-6c05b70b55f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3917,)\n",
      "x_train shape: (3917, 6, 4987, 1)\n",
      "3917 train samples\n",
      "1680 validation samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "img_rows, img_cols = x_train.shape[1], x_train.shape[2]\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0],img_rows,img_cols,1)\n",
    "x_val = x_val.reshape(x_val.shape[0],img_rows,img_cols,1)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_val.shape[0], 'validation samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D5lkAX-OXDyu"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(3,3), activation='relu', input_shape=(img_rows,img_cols,1)))\n",
    "model.add(Conv2D(16, (3, 3),activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3,3), padding='same',activation='relu'))\n",
    "model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "colab_type": "code",
    "id": "7f1V3XzqXDyy",
    "outputId": "0a8cc489-9543-4b95-d724-e20555b2be1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 4, 4985, 16)       160       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 2, 4983, 16)       2320      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 4983, 32)       4640      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 4983, 32)       9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 2491, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 2491, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 79712)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2550816   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 2,567,882\n",
      "Trainable params: 2,567,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "q-s33POTXDy1",
    "outputId": "515597d2-b24a-4e30-d48f-ff86b16229b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3917 samples, validate on 1680 samples\n",
      "Epoch 1/200\n",
      "3917/3917 [==============================] - 12s 3ms/step - loss: 2.1667 - accuracy: 0.2109 - val_loss: 2.0726 - val_accuracy: 0.3369\n",
      "Epoch 2/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 2.0346 - accuracy: 0.3143 - val_loss: 1.8653 - val_accuracy: 0.3738\n",
      "Epoch 3/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.9223 - accuracy: 0.3431 - val_loss: 1.7755 - val_accuracy: 0.3833\n",
      "Epoch 4/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.8355 - accuracy: 0.3975 - val_loss: 1.7423 - val_accuracy: 0.4363\n",
      "Epoch 5/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.7707 - accuracy: 0.4080 - val_loss: 1.7522 - val_accuracy: 0.4506\n",
      "Epoch 6/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.7206 - accuracy: 0.4266 - val_loss: 1.6025 - val_accuracy: 0.4565\n",
      "Epoch 7/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.6872 - accuracy: 0.4457 - val_loss: 1.5654 - val_accuracy: 0.4869\n",
      "Epoch 8/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.6436 - accuracy: 0.4526 - val_loss: 1.5400 - val_accuracy: 0.4815\n",
      "Epoch 9/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.6065 - accuracy: 0.4621 - val_loss: 1.5567 - val_accuracy: 0.4524\n",
      "Epoch 10/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.5861 - accuracy: 0.4552 - val_loss: 1.6174 - val_accuracy: 0.4107\n",
      "Epoch 11/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.5504 - accuracy: 0.4754 - val_loss: 1.5046 - val_accuracy: 0.4780\n",
      "Epoch 12/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.5434 - accuracy: 0.4657 - val_loss: 1.4218 - val_accuracy: 0.4935\n",
      "Epoch 13/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.4977 - accuracy: 0.4943 - val_loss: 1.4595 - val_accuracy: 0.4994\n",
      "Epoch 14/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.4868 - accuracy: 0.4846 - val_loss: 1.4236 - val_accuracy: 0.4833\n",
      "Epoch 15/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.4590 - accuracy: 0.4932 - val_loss: 1.3755 - val_accuracy: 0.4982\n",
      "Epoch 16/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.4585 - accuracy: 0.5001 - val_loss: 1.4247 - val_accuracy: 0.5202\n",
      "Epoch 17/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.4321 - accuracy: 0.5167 - val_loss: 1.4549 - val_accuracy: 0.5268\n",
      "Epoch 18/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.4082 - accuracy: 0.5287 - val_loss: 1.4365 - val_accuracy: 0.5119\n",
      "Epoch 19/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.3843 - accuracy: 0.5254 - val_loss: 1.3500 - val_accuracy: 0.5446\n",
      "Epoch 20/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.3868 - accuracy: 0.5333 - val_loss: 1.3844 - val_accuracy: 0.5310\n",
      "Epoch 21/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.3748 - accuracy: 0.5445 - val_loss: 1.4862 - val_accuracy: 0.5113\n",
      "Epoch 22/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.3717 - accuracy: 0.5507 - val_loss: 1.3599 - val_accuracy: 0.5649\n",
      "Epoch 23/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.3572 - accuracy: 0.5448 - val_loss: 1.4252 - val_accuracy: 0.5429\n",
      "Epoch 24/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.3295 - accuracy: 0.5555 - val_loss: 1.3241 - val_accuracy: 0.5607\n",
      "Epoch 25/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.3300 - accuracy: 0.5494 - val_loss: 1.5392 - val_accuracy: 0.5274\n",
      "Epoch 26/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.3369 - accuracy: 0.5374 - val_loss: 1.3222 - val_accuracy: 0.5673\n",
      "Epoch 27/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.3056 - accuracy: 0.5530 - val_loss: 1.3167 - val_accuracy: 0.5762\n",
      "Epoch 28/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.3019 - accuracy: 0.5578 - val_loss: 1.3509 - val_accuracy: 0.5482\n",
      "Epoch 29/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.2839 - accuracy: 0.5619 - val_loss: 1.3185 - val_accuracy: 0.5815\n",
      "Epoch 30/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.2915 - accuracy: 0.5665 - val_loss: 1.3451 - val_accuracy: 0.5708\n",
      "Epoch 31/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.2834 - accuracy: 0.5599 - val_loss: 1.3215 - val_accuracy: 0.5750\n",
      "Epoch 32/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.2896 - accuracy: 0.5708 - val_loss: 1.3419 - val_accuracy: 0.5738\n",
      "Epoch 33/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.2855 - accuracy: 0.5708 - val_loss: 1.3445 - val_accuracy: 0.5738\n",
      "Epoch 34/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.2782 - accuracy: 0.5624 - val_loss: 1.4405 - val_accuracy: 0.5458\n",
      "Epoch 35/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.2699 - accuracy: 0.5685 - val_loss: 1.4385 - val_accuracy: 0.5494\n",
      "Epoch 36/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.2479 - accuracy: 0.5721 - val_loss: 1.3363 - val_accuracy: 0.5607\n",
      "Epoch 37/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.2534 - accuracy: 0.5678 - val_loss: 1.3214 - val_accuracy: 0.5810\n",
      "Epoch 38/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.2475 - accuracy: 0.5767 - val_loss: 1.3387 - val_accuracy: 0.5726\n",
      "Epoch 39/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.2306 - accuracy: 0.5739 - val_loss: 1.3566 - val_accuracy: 0.5673\n",
      "Epoch 40/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.2185 - accuracy: 0.5790 - val_loss: 1.4615 - val_accuracy: 0.5530\n",
      "Epoch 41/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.2333 - accuracy: 0.5793 - val_loss: 1.3948 - val_accuracy: 0.5631\n",
      "Epoch 42/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.2084 - accuracy: 0.5828 - val_loss: 1.3391 - val_accuracy: 0.5762\n",
      "Epoch 43/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.2126 - accuracy: 0.5798 - val_loss: 1.4046 - val_accuracy: 0.5577\n",
      "Epoch 44/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.2095 - accuracy: 0.5841 - val_loss: 1.3961 - val_accuracy: 0.5589\n",
      "Epoch 45/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.1771 - accuracy: 0.5892 - val_loss: 1.4375 - val_accuracy: 0.5595\n",
      "Epoch 46/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.2027 - accuracy: 0.5854 - val_loss: 1.4006 - val_accuracy: 0.5583\n",
      "Epoch 47/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.1841 - accuracy: 0.5902 - val_loss: 1.3910 - val_accuracy: 0.5655\n",
      "Epoch 48/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.1942 - accuracy: 0.5885 - val_loss: 1.4039 - val_accuracy: 0.5738\n",
      "Epoch 49/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.2027 - accuracy: 0.5902 - val_loss: 1.3603 - val_accuracy: 0.5732\n",
      "Epoch 50/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.1773 - accuracy: 0.5938 - val_loss: 1.3794 - val_accuracy: 0.5780\n",
      "Epoch 51/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.1868 - accuracy: 0.5877 - val_loss: 1.4500 - val_accuracy: 0.5804\n",
      "Epoch 52/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.1752 - accuracy: 0.5974 - val_loss: 1.3746 - val_accuracy: 0.5708\n",
      "Epoch 53/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.1586 - accuracy: 0.5877 - val_loss: 1.5366 - val_accuracy: 0.5708\n",
      "Epoch 54/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.1775 - accuracy: 0.5941 - val_loss: 1.4964 - val_accuracy: 0.5756\n",
      "Epoch 55/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.1758 - accuracy: 0.5839 - val_loss: 1.4001 - val_accuracy: 0.5827\n",
      "Epoch 56/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.1419 - accuracy: 0.6061 - val_loss: 1.4425 - val_accuracy: 0.5810\n",
      "Epoch 57/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.1407 - accuracy: 0.5989 - val_loss: 1.4207 - val_accuracy: 0.5673\n",
      "Epoch 58/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.1541 - accuracy: 0.5915 - val_loss: 1.4730 - val_accuracy: 0.5857\n",
      "Epoch 59/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.1503 - accuracy: 0.5931 - val_loss: 1.4718 - val_accuracy: 0.5661\n",
      "Epoch 60/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.1444 - accuracy: 0.6007 - val_loss: 1.4472 - val_accuracy: 0.5857\n",
      "Epoch 61/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.1366 - accuracy: 0.5987 - val_loss: 1.5032 - val_accuracy: 0.5815\n",
      "Epoch 62/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.1340 - accuracy: 0.5994 - val_loss: 1.5108 - val_accuracy: 0.5435\n",
      "Epoch 63/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.1269 - accuracy: 0.6097 - val_loss: 1.4937 - val_accuracy: 0.5762\n",
      "Epoch 64/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.1274 - accuracy: 0.6068 - val_loss: 1.4759 - val_accuracy: 0.5893\n",
      "Epoch 65/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.0999 - accuracy: 0.6135 - val_loss: 1.4985 - val_accuracy: 0.5673\n",
      "Epoch 66/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.1166 - accuracy: 0.6102 - val_loss: 1.6926 - val_accuracy: 0.5458\n",
      "Epoch 67/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.1079 - accuracy: 0.6079 - val_loss: 1.5133 - val_accuracy: 0.5940\n",
      "Epoch 68/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.1055 - accuracy: 0.6132 - val_loss: 1.5714 - val_accuracy: 0.6077\n",
      "Epoch 69/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.1076 - accuracy: 0.6068 - val_loss: 1.5270 - val_accuracy: 0.6030\n",
      "Epoch 70/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.0951 - accuracy: 0.6173 - val_loss: 1.5318 - val_accuracy: 0.5958\n",
      "Epoch 71/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.1058 - accuracy: 0.6176 - val_loss: 1.4320 - val_accuracy: 0.6012\n",
      "Epoch 72/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.0744 - accuracy: 0.6288 - val_loss: 1.4877 - val_accuracy: 0.6060\n",
      "Epoch 73/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.0774 - accuracy: 0.6283 - val_loss: 1.5139 - val_accuracy: 0.6083\n",
      "Epoch 74/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.0785 - accuracy: 0.6232 - val_loss: 1.5219 - val_accuracy: 0.5810\n",
      "Epoch 75/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.0712 - accuracy: 0.6148 - val_loss: 1.5790 - val_accuracy: 0.6012\n",
      "Epoch 76/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.0893 - accuracy: 0.6178 - val_loss: 1.5949 - val_accuracy: 0.6071\n",
      "Epoch 77/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.0670 - accuracy: 0.6222 - val_loss: 1.5237 - val_accuracy: 0.5935\n",
      "Epoch 78/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.0630 - accuracy: 0.6293 - val_loss: 1.5133 - val_accuracy: 0.5970\n",
      "Epoch 79/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.0700 - accuracy: 0.6194 - val_loss: 1.5780 - val_accuracy: 0.5994\n",
      "Epoch 80/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.0567 - accuracy: 0.6273 - val_loss: 1.5576 - val_accuracy: 0.6131\n",
      "Epoch 81/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.0286 - accuracy: 0.6367 - val_loss: 1.6242 - val_accuracy: 0.6113\n",
      "Epoch 82/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.0565 - accuracy: 0.6275 - val_loss: 1.6386 - val_accuracy: 0.6083\n",
      "Epoch 83/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.0396 - accuracy: 0.6380 - val_loss: 1.5786 - val_accuracy: 0.6125\n",
      "Epoch 84/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.0343 - accuracy: 0.6344 - val_loss: 1.5213 - val_accuracy: 0.6167\n",
      "Epoch 85/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.0235 - accuracy: 0.6482 - val_loss: 1.5125 - val_accuracy: 0.6065\n",
      "Epoch 86/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.0418 - accuracy: 0.6336 - val_loss: 1.4944 - val_accuracy: 0.5970\n",
      "Epoch 87/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.0327 - accuracy: 0.6441 - val_loss: 1.6010 - val_accuracy: 0.6077\n",
      "Epoch 88/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.0204 - accuracy: 0.6342 - val_loss: 1.5263 - val_accuracy: 0.6268\n",
      "Epoch 89/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.0138 - accuracy: 0.6469 - val_loss: 1.6025 - val_accuracy: 0.6113\n",
      "Epoch 90/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.0156 - accuracy: 0.6426 - val_loss: 1.5252 - val_accuracy: 0.6220\n",
      "Epoch 91/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.0081 - accuracy: 0.6490 - val_loss: 1.5174 - val_accuracy: 0.5923\n",
      "Epoch 92/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.0054 - accuracy: 0.6500 - val_loss: 1.5476 - val_accuracy: 0.6208\n",
      "Epoch 93/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.0051 - accuracy: 0.6515 - val_loss: 1.6152 - val_accuracy: 0.6190\n",
      "Epoch 94/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9935 - accuracy: 0.6571 - val_loss: 1.5471 - val_accuracy: 0.6018\n",
      "Epoch 95/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 1.0063 - accuracy: 0.6553 - val_loss: 1.6912 - val_accuracy: 0.6214\n",
      "Epoch 96/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9831 - accuracy: 0.6582 - val_loss: 1.5362 - val_accuracy: 0.6256\n",
      "Epoch 97/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9907 - accuracy: 0.6597 - val_loss: 1.7402 - val_accuracy: 0.6107\n",
      "Epoch 98/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9925 - accuracy: 0.6543 - val_loss: 1.6361 - val_accuracy: 0.6006\n",
      "Epoch 99/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9912 - accuracy: 0.6625 - val_loss: 1.5407 - val_accuracy: 0.6214\n",
      "Epoch 100/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9763 - accuracy: 0.6533 - val_loss: 1.7464 - val_accuracy: 0.6244\n",
      "Epoch 101/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9685 - accuracy: 0.6714 - val_loss: 1.6253 - val_accuracy: 0.6179\n",
      "Epoch 102/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9737 - accuracy: 0.6582 - val_loss: 1.6857 - val_accuracy: 0.6321\n",
      "Epoch 103/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9698 - accuracy: 0.6673 - val_loss: 1.5866 - val_accuracy: 0.6387\n",
      "Epoch 104/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9655 - accuracy: 0.6648 - val_loss: 1.5828 - val_accuracy: 0.6381\n",
      "Epoch 105/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9666 - accuracy: 0.6630 - val_loss: 1.5196 - val_accuracy: 0.6274\n",
      "Epoch 106/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9564 - accuracy: 0.6686 - val_loss: 1.5865 - val_accuracy: 0.6286\n",
      "Epoch 107/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9625 - accuracy: 0.6684 - val_loss: 1.5662 - val_accuracy: 0.6351\n",
      "Epoch 108/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9432 - accuracy: 0.6748 - val_loss: 1.7364 - val_accuracy: 0.6274\n",
      "Epoch 109/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9365 - accuracy: 0.6765 - val_loss: 1.5491 - val_accuracy: 0.6167\n",
      "Epoch 110/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9433 - accuracy: 0.6712 - val_loss: 1.7113 - val_accuracy: 0.6333\n",
      "Epoch 111/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9332 - accuracy: 0.6816 - val_loss: 1.6274 - val_accuracy: 0.6262\n",
      "Epoch 112/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9499 - accuracy: 0.6737 - val_loss: 1.8287 - val_accuracy: 0.6280\n",
      "Epoch 113/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9392 - accuracy: 0.6804 - val_loss: 1.6388 - val_accuracy: 0.6435\n",
      "Epoch 114/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9291 - accuracy: 0.6732 - val_loss: 1.6168 - val_accuracy: 0.6304\n",
      "Epoch 115/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9260 - accuracy: 0.6791 - val_loss: 1.8152 - val_accuracy: 0.6274\n",
      "Epoch 116/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9290 - accuracy: 0.6839 - val_loss: 1.6448 - val_accuracy: 0.6411\n",
      "Epoch 117/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9320 - accuracy: 0.6799 - val_loss: 1.5190 - val_accuracy: 0.6321\n",
      "Epoch 118/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9070 - accuracy: 0.6819 - val_loss: 1.7213 - val_accuracy: 0.6387\n",
      "Epoch 119/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9261 - accuracy: 0.6786 - val_loss: 1.5556 - val_accuracy: 0.6429\n",
      "Epoch 120/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8908 - accuracy: 0.6929 - val_loss: 1.5665 - val_accuracy: 0.6369\n",
      "Epoch 121/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9144 - accuracy: 0.6908 - val_loss: 1.5396 - val_accuracy: 0.6381\n",
      "Epoch 122/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9021 - accuracy: 0.6883 - val_loss: 1.7111 - val_accuracy: 0.6518\n",
      "Epoch 123/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9011 - accuracy: 0.6873 - val_loss: 1.5879 - val_accuracy: 0.6458\n",
      "Epoch 124/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8997 - accuracy: 0.6903 - val_loss: 1.5880 - val_accuracy: 0.6518\n",
      "Epoch 125/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8990 - accuracy: 0.6875 - val_loss: 1.7147 - val_accuracy: 0.6423\n",
      "Epoch 126/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8900 - accuracy: 0.6965 - val_loss: 1.6054 - val_accuracy: 0.6482\n",
      "Epoch 127/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8966 - accuracy: 0.6965 - val_loss: 1.6387 - val_accuracy: 0.6321\n",
      "Epoch 128/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9012 - accuracy: 0.6924 - val_loss: 1.7108 - val_accuracy: 0.6411\n",
      "Epoch 129/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8885 - accuracy: 0.6982 - val_loss: 1.6391 - val_accuracy: 0.6321\n",
      "Epoch 130/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8931 - accuracy: 0.6954 - val_loss: 2.0069 - val_accuracy: 0.6167\n",
      "Epoch 131/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.9064 - accuracy: 0.6942 - val_loss: 1.6207 - val_accuracy: 0.6423\n",
      "Epoch 132/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8880 - accuracy: 0.6972 - val_loss: 1.7403 - val_accuracy: 0.6476\n",
      "Epoch 133/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8648 - accuracy: 0.7062 - val_loss: 1.5895 - val_accuracy: 0.6464\n",
      "Epoch 134/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8825 - accuracy: 0.6995 - val_loss: 1.6217 - val_accuracy: 0.6512\n",
      "Epoch 135/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8696 - accuracy: 0.7036 - val_loss: 1.6705 - val_accuracy: 0.6429\n",
      "Epoch 136/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8770 - accuracy: 0.6929 - val_loss: 1.5776 - val_accuracy: 0.6470\n",
      "Epoch 137/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8612 - accuracy: 0.7054 - val_loss: 1.6711 - val_accuracy: 0.6363\n",
      "Epoch 138/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8668 - accuracy: 0.7005 - val_loss: 1.5912 - val_accuracy: 0.6435\n",
      "Epoch 139/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8885 - accuracy: 0.7008 - val_loss: 1.6016 - val_accuracy: 0.6357\n",
      "Epoch 140/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8583 - accuracy: 0.7097 - val_loss: 1.7680 - val_accuracy: 0.6548\n",
      "Epoch 141/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8692 - accuracy: 0.7010 - val_loss: 1.6982 - val_accuracy: 0.6470\n",
      "Epoch 142/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8408 - accuracy: 0.7026 - val_loss: 1.8429 - val_accuracy: 0.6310\n",
      "Epoch 143/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8393 - accuracy: 0.7054 - val_loss: 1.8544 - val_accuracy: 0.6476\n",
      "Epoch 144/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8386 - accuracy: 0.7204 - val_loss: 1.6742 - val_accuracy: 0.6423\n",
      "Epoch 145/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8496 - accuracy: 0.7146 - val_loss: 1.6295 - val_accuracy: 0.6476\n",
      "Epoch 146/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8349 - accuracy: 0.7105 - val_loss: 1.8603 - val_accuracy: 0.6399\n",
      "Epoch 147/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8452 - accuracy: 0.7107 - val_loss: 1.8573 - val_accuracy: 0.6458\n",
      "Epoch 148/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8197 - accuracy: 0.7176 - val_loss: 1.8400 - val_accuracy: 0.6393\n",
      "Epoch 149/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8289 - accuracy: 0.7199 - val_loss: 1.7318 - val_accuracy: 0.6506\n",
      "Epoch 150/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8466 - accuracy: 0.7146 - val_loss: 1.7790 - val_accuracy: 0.6452\n",
      "Epoch 151/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8300 - accuracy: 0.7204 - val_loss: 1.8651 - val_accuracy: 0.6482\n",
      "Epoch 152/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8097 - accuracy: 0.7199 - val_loss: 1.8938 - val_accuracy: 0.6577\n",
      "Epoch 153/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8241 - accuracy: 0.7187 - val_loss: 1.7523 - val_accuracy: 0.6387\n",
      "Epoch 154/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8325 - accuracy: 0.7092 - val_loss: 1.7414 - val_accuracy: 0.6375\n",
      "Epoch 155/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8160 - accuracy: 0.7199 - val_loss: 1.7515 - val_accuracy: 0.6530\n",
      "Epoch 156/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8196 - accuracy: 0.7220 - val_loss: 1.7409 - val_accuracy: 0.6488\n",
      "Epoch 157/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8345 - accuracy: 0.7169 - val_loss: 1.7638 - val_accuracy: 0.6423\n",
      "Epoch 158/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8170 - accuracy: 0.7204 - val_loss: 1.8356 - val_accuracy: 0.6321\n",
      "Epoch 159/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8077 - accuracy: 0.7289 - val_loss: 1.7762 - val_accuracy: 0.6524\n",
      "Epoch 160/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8165 - accuracy: 0.7136 - val_loss: 1.7885 - val_accuracy: 0.6417\n",
      "Epoch 161/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8205 - accuracy: 0.7107 - val_loss: 1.6660 - val_accuracy: 0.6470\n",
      "Epoch 162/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7950 - accuracy: 0.7271 - val_loss: 1.7917 - val_accuracy: 0.6506\n",
      "Epoch 163/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8181 - accuracy: 0.7199 - val_loss: 1.8185 - val_accuracy: 0.6440\n",
      "Epoch 164/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8037 - accuracy: 0.7296 - val_loss: 1.8829 - val_accuracy: 0.6476\n",
      "Epoch 165/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7868 - accuracy: 0.7276 - val_loss: 1.9807 - val_accuracy: 0.6476\n",
      "Epoch 166/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7965 - accuracy: 0.7220 - val_loss: 1.8547 - val_accuracy: 0.6476\n",
      "Epoch 167/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.8043 - accuracy: 0.7227 - val_loss: 1.5282 - val_accuracy: 0.6393\n",
      "Epoch 168/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7940 - accuracy: 0.7230 - val_loss: 1.7725 - val_accuracy: 0.6423\n",
      "Epoch 169/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7977 - accuracy: 0.7212 - val_loss: 1.7526 - val_accuracy: 0.6321\n",
      "Epoch 170/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7831 - accuracy: 0.7294 - val_loss: 1.6208 - val_accuracy: 0.6417\n",
      "Epoch 171/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7788 - accuracy: 0.7304 - val_loss: 1.8595 - val_accuracy: 0.6435\n",
      "Epoch 172/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7926 - accuracy: 0.7294 - val_loss: 2.0727 - val_accuracy: 0.6292\n",
      "Epoch 173/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7941 - accuracy: 0.7302 - val_loss: 1.8828 - val_accuracy: 0.6429\n",
      "Epoch 174/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7694 - accuracy: 0.7312 - val_loss: 2.0563 - val_accuracy: 0.6399\n",
      "Epoch 175/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7827 - accuracy: 0.7340 - val_loss: 1.7941 - val_accuracy: 0.6399\n",
      "Epoch 176/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7728 - accuracy: 0.7291 - val_loss: 2.0008 - val_accuracy: 0.6435\n",
      "Epoch 177/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7843 - accuracy: 0.7330 - val_loss: 1.8018 - val_accuracy: 0.6542\n",
      "Epoch 178/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7694 - accuracy: 0.7355 - val_loss: 1.9680 - val_accuracy: 0.6327\n",
      "Epoch 179/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7678 - accuracy: 0.7370 - val_loss: 1.9489 - val_accuracy: 0.6423\n",
      "Epoch 180/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7693 - accuracy: 0.7363 - val_loss: 1.8023 - val_accuracy: 0.6446\n",
      "Epoch 181/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7650 - accuracy: 0.7358 - val_loss: 1.8940 - val_accuracy: 0.6214\n",
      "Epoch 182/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7586 - accuracy: 0.7319 - val_loss: 1.8308 - val_accuracy: 0.6250\n",
      "Epoch 183/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7889 - accuracy: 0.7345 - val_loss: 1.9750 - val_accuracy: 0.6399\n",
      "Epoch 184/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7714 - accuracy: 0.7424 - val_loss: 1.6811 - val_accuracy: 0.6423\n",
      "Epoch 185/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7659 - accuracy: 0.7404 - val_loss: 1.8165 - val_accuracy: 0.6476\n",
      "Epoch 186/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7852 - accuracy: 0.7401 - val_loss: 1.9078 - val_accuracy: 0.6315\n",
      "Epoch 187/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7597 - accuracy: 0.7399 - val_loss: 1.9009 - val_accuracy: 0.6452\n",
      "Epoch 188/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7616 - accuracy: 0.7437 - val_loss: 1.8404 - val_accuracy: 0.6446\n",
      "Epoch 189/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7411 - accuracy: 0.7416 - val_loss: 1.9181 - val_accuracy: 0.6446\n",
      "Epoch 190/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7474 - accuracy: 0.7473 - val_loss: 1.9553 - val_accuracy: 0.6405\n",
      "Epoch 191/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7440 - accuracy: 0.7455 - val_loss: 1.6914 - val_accuracy: 0.6399\n",
      "Epoch 192/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7539 - accuracy: 0.7450 - val_loss: 1.8611 - val_accuracy: 0.6500\n",
      "Epoch 193/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7509 - accuracy: 0.7434 - val_loss: 1.8584 - val_accuracy: 0.6470\n",
      "Epoch 194/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7508 - accuracy: 0.7427 - val_loss: 1.8802 - val_accuracy: 0.6488\n",
      "Epoch 195/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7381 - accuracy: 0.7391 - val_loss: 1.9204 - val_accuracy: 0.6363\n",
      "Epoch 196/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7359 - accuracy: 0.7511 - val_loss: 1.9820 - val_accuracy: 0.6488\n",
      "Epoch 197/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7412 - accuracy: 0.7427 - val_loss: 2.0524 - val_accuracy: 0.6554\n",
      "Epoch 198/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7442 - accuracy: 0.7455 - val_loss: 1.7817 - val_accuracy: 0.6345\n",
      "Epoch 199/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7219 - accuracy: 0.7470 - val_loss: 2.0186 - val_accuracy: 0.6500\n",
      "Epoch 200/200\n",
      "3917/3917 [==============================] - 4s 1ms/step - loss: 0.7422 - accuracy: 0.7437 - val_loss: 1.7714 - val_accuracy: 0.6393\n",
      "Test loss: 1.7713914984748478\n",
      "Test accuracy: 0.6392857432365417\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=200, verbose=1, validation_data=(x_val, y_val))\n",
    "score = model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "colab_type": "code",
    "id": "xK9KT8vzXDy8",
    "outputId": "79ae6a96-13ae-4b3a-e6da-63ac9ec27eb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix - Test\n",
      "[[145   0   0   2  20   3  16   6   8  16]\n",
      " [  0   0   0   1   0  14   2   5   3  14]\n",
      " [  3   0   0   0   0  35   4   1   0   0]\n",
      " [  8   0   0  59   1   7   7   9   2  29]\n",
      " [ 10   0   0   3 118   4   1   4   1   3]\n",
      " [  5   0   0   1   0  59   9   3   0   2]\n",
      " [  9   0   0   4   1   5  39  42   6  25]\n",
      " [  8   0   0   5   5   9  24 135   3  48]\n",
      " [ 20   0   0   5   2   2   1   7  54  17]\n",
      " [ 18   0   0  21   1   4   8  36   8 465]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  California       0.64      0.67      0.66       216\n",
      " Connecticut       0.00      0.00      0.00        39\n",
      "     Florida       0.00      0.00      0.00        43\n",
      "Masachusetts       0.58      0.48      0.53       122\n",
      "    Michigan       0.80      0.82      0.81       144\n",
      "    New York       0.42      0.75      0.53        79\n",
      "      Others       0.35      0.30      0.32       131\n",
      "         USA       0.54      0.57      0.56       237\n",
      "    Virginia       0.64      0.50      0.56       108\n",
      "  Washington       0.75      0.83      0.79       561\n",
      "\n",
      "    accuracy                           0.64      1680\n",
      "   macro avg       0.47      0.49      0.48      1680\n",
      "weighted avg       0.61      0.64      0.62      1680\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(x_val)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion matrix - Test')\n",
    "y_val2 = np.argmax(y_val,axis=1)\n",
    "print(confusion_matrix(y_val2,y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['California','Connecticut','Florida','Masachusetts','Michigan','New York','Others','USA','Virginia','Washington']\n",
    "print(classification_report(y_val2, y_pred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
